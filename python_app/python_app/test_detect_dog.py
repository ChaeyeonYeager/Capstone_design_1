# ë¯¸ë¦¬ ì €ì¥ëœ ì˜ìƒì„ ë¶„ì„í•˜ì—¬ result_videoì— ì €ì¥

# # test_videos/ì˜ ëª¨ë“  ë™ì˜ìƒ(.mp4/.mov/.avi/.mkv)ì„ ì½ì–´
# # ê²°ê³¼ë¥¼ result_videos/ì›ë³¸ì´ë¦„_result.mp4ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

# # ê° ë°•ìŠ¤ì—ëŠ” Dog, MatchScore, ID_Conf(%) , YOLO_Conf(%) , Sizeë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.

# # pet_db.jsonì´ ìˆìœ¼ë©´ size ì •ë³´ë„ í•¨ê»˜ í‘œê¸°í•©ë‹ˆë‹¤(ì—†ì–´ë„ ë™ì‘).




# # test_detect_dogs.py
# # test_videos/ì˜ ëª¨ë“  ë™ì˜ìƒ(.mp4/.mov/.avi/.mkv)ì„ ë¶„ì„í•´
# # result_videos/ì›ë³¸ì´ë¦„_result.mp4ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
# # ê° ë°•ìŠ¤ì—ëŠ” Dog, MatchScore, ID_Conf(%), YOLO_Conf(%), Sizeë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
# # pet_db.jsonì´ ìˆìœ¼ë©´ size ì •ë³´ë„ í•¨ê»˜ í‘œê¸°í•©ë‹ˆë‹¤(ì—†ì–´ë„ ë™ì‘).

# import os
# import json
# import time
# import argparse
# import cv2
# from ultralytics import YOLO
# from test_embedding_utils import load_registered_images, match_dog

# DOG_CLASS_ID = 16  # COCO dataset: dog
# VIDEO_EXTS = (".mp4", ".mov", ".avi", ".mkv")

# # ğŸ”  í•œê¸€ â†’ ì˜ì–´ ì´ë¦„ ë§¤í•‘
# NAME_MAP = {
#     "ê¹Œë¯¸": "Kami",
#     "ë˜˜ì´": "Ddori",
#     "ìœ¨ë¬´": "Yulmu",
#     "í•˜íŠ¸": "Heart",
#     "ì„¤ê¸°": "Seolgi",
#     "ì½©ì´": "Kong",
#     "ì‚ì‚": "Pippi",
#     "ì¿ í‚¤": "Cookie"
# }

# def list_videos(input_dir):
#     """í•˜ìœ„ í´ë”ê¹Œì§€ ëª¨ë‘ íƒìƒ‰"""
#     files = []
#     if not os.path.isdir(input_dir):
#         print(f"[ERROR] ì…ë ¥ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
#         return files
#     for root, _, fnames in os.walk(input_dir):
#         for fname in sorted(fnames):
#             if fname.lower().endswith(VIDEO_EXTS):
#                 files.append(os.path.join(root, fname))
#     return files


# def safe_rect(x1, y1, x2, y2, w, h):
#     x1 = max(0, min(int(x1), w-1))
#     y1 = max(0, min(int(y1), h-1))
#     x2 = max(0, min(int(x2), w-1))
#     y2 = max(0, min(int(y2), h-1))
#     if x2 <= x1: x2 = min(w-1, x1+1)
#     if y2 <= y1: y2 = min(h-1, y1+1)
#     return x1, y1, x2, y2


# def main(
#     input_dir="test_videos",
#     output_dir="result_videos",
#     pet_dir="pet_images",
#     pet_db_path="pet_db.json",
#     yolo_weights="yolov8n.pt",
#     yolo_conf=0.25,
#     device=None
# ):
#     os.makedirs(output_dir, exist_ok=True)

#     # ----- pet_db ë¡œë“œ -----
#     pet_db = {}
#     if os.path.isfile(pet_db_path):
#         try:
#             with open(pet_db_path, "r", encoding="utf-8") as f:
#                 pet_db = json.load(f)
#                 print(f"[INFO] pet_db ë¡œë“œ: {len(pet_db)}ë§ˆë¦¬")
#         except Exception as e:
#             print("[WARN] pet_db.json ë¡œë“œ ì‹¤íŒ¨:", e)

#     # ----- ë“±ë¡ ì´ë¯¸ì§€ ë¡œë“œ -----
#     registered = load_registered_images(pet_dir, verbose=True)
#     print(f"[INFO] ë“±ë¡ëœ ê°•ì•„ì§€ ìˆ˜: {len(registered)}")

#     # ----- YOLO ëª¨ë¸ ë¡œë“œ -----
#     model = YOLO(yolo_weights)
#     if device is not None:
#         try:
#             model.to(device)
#             print(f"[INFO] YOLO device: {device}")
#         except Exception as e:
#             print("[WARN] device ì„¤ì • ì‹¤íŒ¨(ë¬´ì‹œ):", e)

#     # ----- ì…ë ¥ ì˜ìƒ ë¦¬ìŠ¤íŠ¸ -----
#     videos = list_videos(input_dir)
#     if not videos:
#         print(f"[ERROR] ì²˜ë¦¬í•  ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
#         return

#     for vpath in videos:
#         vname = os.path.basename(vpath)
#         out_path = os.path.join(
#             output_dir,
#             os.path.splitext(vname)[0] + "_result.mp4"
#         )
#         print(f"\n[PROCESS] {vname} -> {out_path}")

#         cap = cv2.VideoCapture(vpath)
#         if not cap.isOpened():
#             print(f"[ERROR] ì—´ ìˆ˜ ì—†ëŠ” ì˜ìƒ: {vpath}")
#             continue

#         # ì›ë³¸ ì˜ìƒ ì •ë³´
#         width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
#         height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
#         fps    = cap.get(cv2.CAP_PROP_FPS) or 30.0
#         fourcc = cv2.VideoWriter_fourcc(*"mp4v")
#         writer = cv2.VideoWriter(out_path, fourcc, fps, (width, height))

#         frame_idx = 0
#         t0 = time.time()

#         while True:
#             ret, frame = cap.read()
#             if not ret:
#                 break
#             frame_idx += 1

#             # YOLO ì¶”ë¡ 
#             results = model(frame, conf=yolo_conf, verbose=False)
#             boxes = results[0].boxes

#             # ê¸°ë³¸ ì•ˆë‚´ ë¬¸êµ¬(íƒì§€ ì‹¤íŒ¨ ëŒ€ë¹„)
#             base_text = "No dog detected"
#             base_color = (0, 0, 255)
#             drawn = False

#             if boxes is not None and len(boxes) > 0:
#                 xyxy = boxes.xyxy.cpu().numpy()
#                 cls  = boxes.cls.cpu().numpy()
#                 conf = boxes.conf.cpu().numpy()

#                 for i in range(len(xyxy)):
#                     if int(cls[i]) != DOG_CLASS_ID:
#                         continue
#                     x1, y1, x2, y2 = xyxy[i]
#                     yolo_c = conf[i]
#                     x1, y1, x2, y2 = safe_rect(x1, y1, x2, y2, width, height)
#                     roi = frame[y1:y2, x1:x2]

#                     name, match_score, id_conf = match_dog(roi, registered)
#                     size = pet_db.get(name, {}).get("size", "unknown") if name else "unknown"

#                     # ----- ì´ë¦„ ë³€í™˜ (í•œê¸€ â†’ ì˜ì–´) -----
#                     label_name = NAME_MAP.get(name, name if name else "Unknown")

#                     if name:
#                         color = (0, 255, 0)
#                         label = f"Dog: {label_name} | Match: {match_score} | ID_Conf: {id_conf}% | YOLO_Conf: {int(yolo_c*100)}% | Size: {size}"
#                     else:
#                         color = (0, 0, 255)
#                         label = f"Dog: None | Match: 0 | ID_Conf: 0% | YOLO_Conf: {int(yolo_c*100)}%"

#                     # ì‹œê°í™”
#                     cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
#                     cv2.putText(frame, label, (x1, max(20, y1-10)),
#                                 cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
#                     drawn = True

#             # ë°•ìŠ¤ê°€ ì—†ì„ ë•Œ ê¸°ë³¸ ë¬¸êµ¬ ì¶œë ¥
#             if not drawn:
#                 cv2.putText(frame, base_text, (20, 40),
#                             cv2.FONT_HERSHEY_SIMPLEX, 1.0, base_color, 2)

#             # FPS í‘œì‹œ
#             elapsed = max(1e-6, (time.time() - t0))
#             fps_est = frame_idx / elapsed
#             cv2.putText(frame, f"FPS: {fps_est:.1f}", (20, height - 20),
#                         cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

#             writer.write(frame)

#         cap.release()
#         writer.release()
#         print(f"[DONE] ì €ì¥ ì™„ë£Œ: {out_path}")


# if __name__ == "__main__":
#     ap = argparse.ArgumentParser()
#     ap.add_argument("--input_dir", default="test_videos")
#     ap.add_argument("--output_dir", default="result_videos")
#     ap.add_argument("--pet_dir", default="pet_images")
#     ap.add_argument("--pet_db", dest="pet_db_path", default="pet_db.json")
#     ap.add_argument("--weights", dest="yolo_weights", default="yolov8n.pt")
#     ap.add_argument("--conf", dest="yolo_conf", type=float, default=0.25)
#     ap.add_argument("--device", default=None, help="cuda:0 / mps / cpu ë“± (ì„ íƒ)")
#     args = ap.parse_args()

#     main(
#         input_dir=args.input_dir,
#         output_dir=args.output_dir,
#         pet_dir=args.pet_dir,
#         pet_db_path=args.pet_db_path,
#         yolo_weights=args.yolo_weights,
#         yolo_conf=args.yolo_conf,
#         device=args.device
#     )

# # test_detect_dogs.py
# import os, json, time, argparse, cv2, math
# from collections import deque
# from ultralytics import YOLO
# from test_embedding_utils import load_registered_images, match_dog

# DOG_CLASS_ID = 16
# VIDEO_EXTS = (".mp4", ".mov", ".avi", ".mkv")
# NAME_MAP = {
#     "ê¹Œë¯¸": "Kami","ë˜˜ì´": "Ddori","ìœ¨ë¬´": "Yulmu","í•˜íŠ¸": "Heart",
#     "ì„¤ê¸°": "Seolgi","ì½©ì´": "Kong","ì‚ì‚": "Pippi","ì¿ í‚¤": "Cookie"
# }

# from collections import deque
# import math, time

# class IdentityStabilizer:
#     def __init__(self, confirm_frames=5, hold_frames=10, iou_thresh=0.1, ema_alpha=0.4):
#         self.confirm_frames = confirm_frames
#         self.hold_frames = hold_frames
#         self.iou_thresh = iou_thresh
#         self.ema_alpha = ema_alpha
#         self.buf = deque(maxlen=confirm_frames)

#         self.lock_name = None
#         self.lock_conf = 0
#         self.miss = 0
#         self.last_box = None

#         # í™•ì • ê´€ë ¨
#         self.detect_start_time = None
#         self.confirmed_once = False  # ì´ë¯¸ í™•ì • ì¶œë ¥í–ˆëŠ”ì§€

#     @staticmethod
#     def _iou(a, b):
#         if a is None or b is None: return 0.0
#         ax1, ay1, ax2, ay2 = a; bx1, by1, bx2, by2 = b
#         iw = max(0, min(ax2, bx2) - max(ax1, bx1))
#         ih = max(0, min(ay2, by2) - max(ay1, by1))
#         inter = iw * ih
#         area_a = max(0, (ax2-ax1)) * max(0, (ay2-ay1))
#         area_b = max(0, (bx2-bx1)) * max(0, (by2-by1))
#         denom = area_a + area_b - inter + 1e-6
#         return inter / denom

#     def update(self, name, conf, box):
#         """
#         name: í˜„ì¬ í”„ë ˆì„ ì¶”ì • ì´ë¦„(or None)
#         conf: í˜„ì¬ í”„ë ˆì„ ID ì‹ ë¢°ë„(0~100)
#         box:  (x1,y1,x2,y2)
#         return: (display_name, display_conf, locked_bool)
#         """
#         now = time.time()

#         # ì²« íƒì§€ ì‹œì‘ ì‹œê° ê¸°ë¡
#         if name and self.detect_start_time is None:
#             self.detect_start_time = now

#         # ìƒˆ ì´ë¦„ì´ë©´ ë²„í¼ ì¶”ê°€
#         if name:
#             self.buf.append((name, conf))

#         # ---- ì´ë¯¸ ë½ì´ ì¡íŒ ìƒíƒœ ----
#         if self.lock_name:
#             if name == self.lock_name and self._iou(self.last_box, box) >= self.iou_thresh:
#                 self.lock_conf = int(self.ema_alpha * conf + (1-self.ema_alpha) * self.lock_conf)
#                 self.miss = 0
#             else:
#                 self.miss += 1
#                 if self.miss >= self.hold_frames:
#                     print(f"[INFO] '{self.lock_name}' ì„¸ì…˜ ì¢…ë£Œ.")
#                     self.lock_name, self.lock_conf = None, 0
#                     self.buf.clear()
#                     self.detect_start_time = None
#                     self.confirmed_once = False
#         # ---- ì•„ì§ ë½ì´ ì—†ìŒ â†’ í™•ì • ì‹œë„ ----
#         else:
#             if len(self.buf) == self.buf.maxlen:
#                 names = [n for n,_ in self.buf]
#                 cand = max(set(names), key=names.count)
#                 freq = names.count(cand)
#                 if freq >= math.ceil(self.confirm_frames*0.6):
#                     avg_conf = int(sum(c for n,c in self.buf if n==cand) / freq)
#                     self.lock_name, self.lock_conf = cand, avg_conf
#                     self.miss = 0
#                     self.buf.clear()

#                     # ğŸ’¡ í™•ì • ì™„ë£Œ ì‹œì  ì¶œë ¥
#                     if self.detect_start_time and not self.confirmed_once:
#                         elapsed = now - self.detect_start_time
#                         print(f"[CONFIRM] '{cand}' í™•ì •ë¨ â€” ì†Œìš”ì‹œê°„: {elapsed:.2f}ì´ˆ, í‰ê·  ì‹ ë¢°ë„ {avg_conf}%")
#                         self.confirmed_once = True

#         disp_name = self.lock_name if self.lock_name else (name or None)
#         disp_conf = self.lock_conf if self.lock_name else (conf if name else 0)
#         self.last_box = box if name else self.last_box
#         return disp_name, disp_conf, (self.lock_name is not None)


# def list_videos(input_dir):
#     files = []
#     if not os.path.isdir(input_dir):
#         print(f"[ERROR] ì…ë ¥ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
#         return files
#     for root, _, fnames in os.walk(input_dir):
#         for fname in sorted(fnames):
#             if fname.lower().endswith(VIDEO_EXTS):
#                 files.append(os.path.join(root, fname))
#     return files

# def safe_rect(x1, y1, x2, y2, w, h):
#     x1 = max(0, min(int(x1), w-1)); y1 = max(0, min(int(y1), h-1))
#     x2 = max(0, min(int(x2), w-1)); y2 = max(0, min(int(y2), h-1))
#     if x2 <= x1: x2 = min(w-1, x1+1)
#     if y2 <= y1: y2 = min(h-1, y1+1)
#     return x1, y1, x2, y2

# def main(input_dir="test_videos", output_dir="result_videos",
#          pet_dir="pet_images", pet_db_path="pet_db.json",
#          yolo_weights="yolov8n.pt", yolo_conf=0.25, device=None):
#     os.makedirs(output_dir, exist_ok=True)

#     pet_db = {}
#     if os.path.isfile(pet_db_path):
#         try:
#             with open(pet_db_path, "r", encoding="utf-8") as f:
#                 pet_db = json.load(f)
#                 print(f"[INFO] pet_db ë¡œë“œ: {len(pet_db)}ë§ˆë¦¬")
#         except Exception as e:
#             print("[WARN] pet_db.json ë¡œë“œ ì‹¤íŒ¨:", e)

#     registered = load_registered_images(pet_dir, verbose=True)
#     print(f"[INFO] ë“±ë¡ëœ ê°•ì•„ì§€ ìˆ˜: {len(registered)}")

#     model = YOLO(yolo_weights)
#     if device is not None:
#         try:
#             model.to(device); print(f"[INFO] YOLO device: {device}")
#         except Exception as e:
#             print("[WARN] device ì„¤ì • ì‹¤íŒ¨(ë¬´ì‹œ):", e)

#     videos = list_videos(input_dir)
#     if not videos:
#         print(f"[ERROR] ì²˜ë¦¬í•  ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
#         return

#     for vpath in videos:
#         vname = os.path.basename(vpath)
#         out_path = os.path.join(output_dir, os.path.splitext(vname)[0] + "_result.mp4")
#         print(f"\n[PROCESS] {vname} -> {out_path}")

#         cap = cv2.VideoCapture(vpath)
#         if not cap.isOpened():
#             print(f"[ERROR] ì—´ ìˆ˜ ì—†ëŠ” ì˜ìƒ: {vpath}")
#             continue

#         width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
#         height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
#         fps    = cap.get(cv2.CAP_PROP_FPS) or 30.0
#         fourcc = cv2.VideoWriter_fourcc(*"mp4v")
#         writer = cv2.VideoWriter(out_path, fourcc, fps, (width, height))

#         frame_idx = 0
#         t0 = time.time()

#         stabilizer = IdentityStabilizer(confirm_frames=5, hold_frames=10, iou_thresh=0.1, ema_alpha=0.4)

#         while True:
#             ret, frame = cap.read()
#             if not ret: break
#             frame_idx += 1

#             results = model(frame, conf=yolo_conf, verbose=False)
#             boxes = results[0].boxes

#             base_text, base_color = "No dog detected", (0, 0, 255)
#             drawn = False

#             if boxes is not None and len(boxes) > 0:
#                 xyxy = boxes.xyxy.cpu().numpy()
#                 cls  = boxes.cls.cpu().numpy()
#                 conf = boxes.conf.cpu().numpy()

#                 for i in range(len(xyxy)):
#                     if int(cls[i]) != DOG_CLASS_ID: continue
#                     x1, y1, x2, y2 = xyxy[i]
#                     yolo_c = conf[i]
#                     x1, y1, x2, y2 = safe_rect(x1, y1, x2, y2, width, height)
#                     roi = frame[y1:y2, x1:x2]

#                     name, match_score, id_conf = match_dog(roi, registered)
#                     st_name, st_conf, locked = stabilizer.update(name, id_conf, (x1, y1, x2, y2))
#                     size = pet_db.get(st_name, {}).get("size", "unknown") if st_name else "unknown"

#                     if st_name:
#                         color = (0, 255, 0)
#                         label_name = NAME_MAP.get(st_name, st_name)
#                         label = f"Dog: {label_name} | ID_Conf: {st_conf}% | YOLO_Conf: {int(yolo_c*100)}% | Size: {size}"
#                     else:
#                         color = (0, 0, 255)
#                         label = f"Dog: None | ID_Conf: 0% | YOLO_Conf: {int(yolo_c*100)}%"

#                     cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
#                     cv2.putText(frame, label, (x1, max(20, y1-10)),
#                                 cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
#                     drawn = True

#             if not drawn:
#                 cv2.putText(frame, base_text, (20, 40),
#                             cv2.FONT_HERSHEY_SIMPLEX, 1.0, base_color, 2)

#             elapsed = max(1e-6, (time.time() - t0))
#             fps_est = frame_idx / elapsed
#             cv2.putText(frame, f"FPS: {fps_est:.1f}", (20, height - 20),
#                         cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)

#             writer.write(frame)

#         cap.release()
#         writer.release()
#         print(f"[DONE] ì €ì¥ ì™„ë£Œ: {out_path}")

# if __name__ == "__main__":
#     ap = argparse.ArgumentParser()
#     ap.add_argument("--input_dir", default="test_videos")
#     ap.add_argument("--output_dir", default="result_videos")
#     ap.add_argument("--pet_dir", default="pet_images")
#     ap.add_argument("--pet_db", dest="pet_db_path", default="pet_db.json")
#     ap.add_argument("--weights", dest="yolo_weights", default="yolov8n.pt")
#     ap.add_argument("--conf", dest="yolo_conf", type=float, default=0.25)
#     ap.add_argument("--device", default=None, help="cuda:0 / mps / cpu")
#     args = ap.parse_args()

#     main(
#         input_dir=args.input_dir,
#         output_dir=args.output_dir,
#         pet_dir=args.pet_dir,
#         pet_db_path=args.pet_db_path,
#         yolo_weights=args.yolo_weights,
#         yolo_conf=args.yolo_conf,
#         device=args.device
#     )


# test_detect_dogs.py
# test_videos/ í•˜ìœ„ ëª¨ë“  ì˜ìƒ(.mp4/.mov/.avi/.mkv)ì„ ì½ì–´
# result_videos/ì›ë³¸ì´ë¦„_result.mp4ë¡œ ì €ì¥ + í™•ì • ì‹œê°(ms) ìš”ì•½ ì¶œë ¥

# import os
# import json
# import time
# import argparse
# import cv2
# from ultralytics import YOLO

# from test_embedding_utils import load_registered_images, match_dog

# DOG_CLASS_ID = 16  # COCO: dog
# VIDEO_EXTS = (".mp4", ".mov", ".avi", ".mkv")

# # í™•ì •(confirmation) ê¸°ì¤€
# YOLO_MIN_CONF = 0.20   # YOLO í™•ì‹ ë„ ìµœì†Œ (0~1)
# ID_MIN_CONF   = 10     # ORB ID ì‹ ë¢°ë„ ìµœì†Œ (0~100)
# CONFIRM_N     = 3      # ê°™ì€ ì´ë¦„ì´ Ní”„ë ˆì„ ì—°ì†ì´ë©´ 'í™•ì •'

# def list_videos(input_dir):
#     files = []
#     if not os.path.isdir(input_dir):
#         print(f"[ERROR] ì…ë ¥ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
#         return files
#     # í•˜ìœ„ í´ë”ê¹Œì§€ ëª¨ë‘ íƒìƒ‰
#     for root, _, fnames in os.walk(input_dir):
#         for fname in sorted(fnames):
#             if fname.lower().endswith(VIDEO_EXTS):
#                 files.append(os.path.join(root, fname))
#     return files

# def safe_rect(x1, y1, x2, y2, w, h):
#     x1 = max(0, min(int(x1), w-1))
#     y1 = max(0, min(int(y1), h-1))
#     x2 = max(0, min(int(x2), w-1))
#     y2 = max(0, min(int(y2), h-1))
#     if x2 <= x1: x2 = min(w-1, x1+1)
#     if y2 <= y1: y2 = min(h-1, y1+1)
#     return x1, y1, x2, y2

# def robust_match(roi_bgr, registered):
#     """match_dogì´ (name, score) ë˜ëŠ” (name, score, id_conf) ë‘˜ ë‹¤ ëŒ€ì‘."""
#     name, score, id_conf = None, 0, 0
#     try:
#         out = match_dog(roi_bgr, registered)
#         if isinstance(out, tuple):
#             if len(out) == 3:
#                 name, score, id_conf = out
#             elif len(out) == 2:
#                 name, score = out
#                 id_conf = max(0, min(100, int(score)))
#             else:
#                 name = out[0] if len(out) > 0 else None
#                 score = out[1] if len(out) > 1 else 0
#                 id_conf = max(0, min(100, int(score)))
#     except Exception:
#         pass
#     return name, int(score), int(id_conf)

# def main(
#     input_dir="test_videos",
#     output_dir="result_videos",
#     pet_dir="pet_images",
#     pet_db_path="pet_db.json",
#     yolo_weights="yolov8n.pt",
#     yolo_conf=0.25,
#     device=None
# ):
#     os.makedirs(output_dir, exist_ok=True)

#     # ê°•ì•„ì§€ DB(ì„ íƒ)
#     pet_db = {}
#     if os.path.isfile(pet_db_path):
#         try:
#             with open(pet_db_path, "r", encoding="utf-8") as f:
#                 pet_db = json.load(f)
#                 print(f"[INFO] pet_db ë¡œë“œ: {len(pet_db)}ë§ˆë¦¬")
#         except Exception as e:
#             print("[WARN] pet_db.json ë¡œë“œ ì‹¤íŒ¨:", e)

#     # ë“±ë¡ ì´ë¯¸ì§€ ë¡œë“œ
#     registered = load_registered_images(pet_dir, verbose=True)
#     print(f"[INFO] ë“±ë¡ëœ ê°•ì•„ì§€ ìˆ˜: {len(registered)}")

#     # YOLO ë¡œë“œ
#     model = YOLO(yolo_weights)
#     if device is not None:
#         try:
#             model.to(device)
#             print(f"[INFO] YOLO device: {device}")
#         except Exception as e:
#             print("[WARN] device ì„¤ì • ì‹¤íŒ¨(ë¬´ì‹œí•˜ê³  ìë™ ì„ íƒ):", e)

#     videos = list_videos(input_dir)
#     if not videos:
#         print(f"[ERROR] ì²˜ë¦¬í•  ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
#         return

#     for vpath in videos:
#         vname = os.path.basename(vpath)
#         out_path = os.path.join(
#             output_dir,
#             os.path.splitext(vname)[0] + "_result.mp4"
#         )
#         print(f"\n[PROCESS] {vname} -> {out_path}")

#         cap = cv2.VideoCapture(vpath)
#         if not cap.isOpened():
#             print(f"[ERROR] ì—´ ìˆ˜ ì—†ëŠ” ì˜ìƒ: {vpath}")
#             continue

#         width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
#         height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
#         fps    = cap.get(cv2.CAP_PROP_FPS) or 30.0
#         fourcc = cv2.VideoWriter_fourcc(*"mp4v")
#         writer = cv2.VideoWriter(out_path, fourcc, fps, (width, height))

#         # íƒ€ì´ë° ê¸°ì¤€: "ì˜ìƒ ì‹œì‘ë¶€í„° í™•ì •ê¹Œì§€"
#         t0 = time.time()
#         confirmed_ms = None
#         confirmed_name = None
#         # ì—°ì† í™•ì¸ ë²„í¼
#         confirm_buf = []

#         frame_idx = 0
#         while True:
#             ret, frame = cap.read()
#             if not ret:
#                 break
#             frame_idx += 1

#             results = model(frame, conf=yolo_conf, verbose=False)
#             boxes = results[0].boxes

#             base_text = "No dog detected"
#             base_color = (0, 0, 255)
#             drawn = False

#             best = None  # ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ë°•ìŠ¤ ì„ íƒ
#             if boxes is not None and len(boxes) > 0:
#                 xyxy = boxes.xyxy.cpu().numpy()
#                 cls  = boxes.cls.cpu().numpy()
#                 conf = boxes.conf.cpu().numpy()

#                 for i in range(len(xyxy)):
#                     if int(cls[i]) != DOG_CLASS_ID:
#                         continue
#                     x1, y1, x2, y2 = xyxy[i]
#                     yolo_c = float(conf[i])
#                     x1, y1, x2, y2 = safe_rect(x1, y1, x2, y2, width, height)
#                     roi = frame[y1:y2, x1:x2]

#                     name, match_score, id_conf = robust_match(roi, registered)
#                     size = pet_db.get(name, {}).get("size", "unknown") if name else "unknown"

#                     # ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ í›„ë³´ ì €ì¥
#                     if best is None or yolo_c > best["yolo_c"]:
#                         best = {
#                             "name": name,
#                             "yolo_c": yolo_c,
#                             "id_conf": id_conf,
#                             "match_score": match_score,
#                             "rect": (x1, y1, x2, y2),
#                             "size": size
#                         }

#             # í™•ì • ë¡œì§ ì²˜ë¦¬
#             if confirmed_ms is None:
#                 if best is not None \
#                    and best["name"] is not None \
#                    and best["yolo_c"] >= YOLO_MIN_CONF \
#                    and best["id_conf"] >= ID_MIN_CONF:
#                     confirm_buf.append(best["name"])
#                     if len(confirm_buf) > CONFIRM_N:
#                         confirm_buf.pop(0)
#                     if len(confirm_buf) == CONFIRM_N and len(set(confirm_buf)) == 1:
#                         confirmed_ms = int((time.time() - t0) * 1000)
#                         confirmed_name = confirm_buf[-1]
#                         print(f"[SUMMARY] {vname} confirmed_at={confirmed_ms}ms "
#                               f"(name={confirmed_name}, frames={CONFIRM_N})")
#                 else:
#                     # ì¡°ê±´ ë¯¸ì¶©ì¡±ì´ë©´ ë²„í¼ ì´ˆê¸°í™”(ëŠê¹€ ë°©ì§€í•˜ë ¤ë©´ ì£¼ì„ ì²˜ë¦¬ ê°€ëŠ¥)
#                     confirm_buf.clear()

#             # ì‹œê°í™”
#             if best is not None:
#                 x1, y1, x2, y2 = best["rect"]
#                 if confirmed_ms is not None:
#                     color = (0, 255, 0)
#                     label = (f"CONFIRMED: {confirmed_name} | "
#                              f"ID_Conf: {best['id_conf']}% | YOLO_Conf: {int(best['yolo_c']*100)}% "
#                              f"| Size: {best['size']}")
#                 else:
#                     color = (0, 165, 255)  # ì£¼í™©: í›„ë³´ ë‹¨ê³„
#                     label = (f"Candidate: {best['name'] or 'None'} | "
#                              f"ID_Conf: {best['id_conf']}% | YOLO_Conf: {int(best['yolo_c']*100)}% "
#                              f"| Size: {best['size']}")
#                 cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
#                 cv2.putText(frame, label, (x1, max(20, y1-10)),
#                             cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
#                 drawn = True

#             if not drawn:
#                 cv2.putText(frame, base_text, (20, 40),
#                             cv2.FONT_HERSHEY_SIMPLEX, 1.0, base_color, 2)

#             # FPS í‘œì‹œ(ëŒ€ëµ)
#             elapsed = max(1e-6, (time.time() - t0))
#             fps_est = frame_idx / elapsed
#             cv2.putText(frame, f"FPS: {fps_est:.1f}", (20, height - 20),
#                         cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

#             writer.write(frame)

#         cap.release()
#         writer.release()
#         print(f"[DONE] ì €ì¥ ì™„ë£Œ: {out_path}")
#         # í™•ì •ì´ ëê¹Œì§€ í•œ ë²ˆë„ ì•ˆ ë˜ë©´ Noneìœ¼ë¡œ ë‚¨ìŒ
#         if confirmed_ms is None:
#             print(f"[SUMMARY] {vname} confirmed_at=None (no stable confirmation)")

# if __name__ == "__main__":
#     ap = argparse.ArgumentParser()
#     ap.add_argument("--input_dir", default="test_videos")
#     ap.add_argument("--output_dir", default="result_videos")
#     ap.add_argument("--pet_dir", default="pet_images")
#     ap.add_argument("--pet_db", dest="pet_db_path", default="pet_db.json")
#     ap.add_argument("--weights", dest="yolo_weights", default="yolov8n.pt")
#     ap.add_argument("--conf", dest="yolo_conf", type=float, default=0.25)
#     ap.add_argument("--device", default=None, help="cuda:0 / mps / cpu ë“± (ì„ íƒ)")
#     args = ap.parse_args()

#     main(
#         input_dir=args.input_dir,
#         output_dir=args.output_dir,
#         pet_dir=args.pet_dir,
#         pet_db_path=args.pet_db_path,
#         yolo_weights=args.yolo_weights,
#         yolo_conf=args.yolo_conf,
#         device=args.device
#     )


# # test_detect_dog.py
# import os
# import json
# import time
# import argparse
# import cv2
# import numpy as np
# import torch
# import torchvision.transforms as T
# from torchvision import models
# from ultralytics import YOLO

# from test_embedding_utils import (
#     load_registered_images,        # ORB descriptors
#     load_registered_color_images,  # BGR images for breed embedding
#     match_dog
# )

# DOG_CLASS_ID = 16  # COCO: dog
# VIDEO_EXTS = (".mp4", ".mov", ".avi", ".mkv")

# # í™•ì •(confirmation) ê¸°ì¤€
# YOLO_MIN_CONF    = 0.20   # YOLO í™•ì‹ ë„ ìµœì†Œ (0~1)
# ID_MIN_CONF      = 10     # ORB ID ì‹ ë¢°ë„ ìµœì†Œ (0~100)
# BREED_MIN_CONF   = 0.35   # í’ˆì¢… ì„ë² ë”© ì •ê·œí™” ì ìˆ˜(0~1)
# CONFIRM_N        = 3      # ê°™ì€ ê²°ê³¼ê°€ Ní”„ë ˆì„ ì—°ì†ì´ë©´ 'í™•ì •'

# # -------------------- ìœ í‹¸ --------------------
# def list_videos(input_dir):
#     files = []
#     if not os.path.isdir(input_dir):
#         print(f"[ERROR] ì…ë ¥ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
#         return files
#     for root, _, fnames in os.walk(input_dir):
#         for fname in sorted(fnames):
#             if fname.lower().endswith(VIDEO_EXTS):
#                 files.append(os.path.join(root, fname))
#     return files

# def safe_rect(x1, y1, x2, y2, w, h):
#     x1 = max(0, min(int(x1), w-1))
#     y1 = max(0, min(int(y1), h-1))
#     x2 = max(0, min(int(x2), w-1))
#     y2 = max(0, min(int(y2), h-1))
#     if x2 <= x1: x2 = min(w-1, x1+1)
#     if y2 <= y1: y2 = min(h-1, y1+1)
#     return x1, y1, x2, y2

# def robust_match(roi_bgr, registered, allowed_names=None):
#     """
#     match_dogì´ (name, score) ë˜ëŠ” (name, score, id_conf) ë‘˜ ë‹¤ ëŒ€ì‘.
#     allowed_namesê°€ ì£¼ì–´ì§€ë©´ ê·¸ ì´ë¦„ë“¤ë§Œ ëŒ€ìƒìœ¼ë¡œ ì œí•œ.
#     """
#     subset = registered
#     if allowed_names is not None:
#         subset = {k: v for k, v in registered.items() if k in allowed_names}

#     name, score, id_conf = None, 0, 0
#     try:
#         out = match_dog(roi_bgr, subset)
#         if isinstance(out, tuple):
#             if len(out) == 3:
#                 name, score, id_conf = out
#             elif len(out) == 2:
#                 name, score = out
#                 id_conf = max(0, min(100, int(score)))
#             else:
#                 name = out[0] if len(out) > 0 else None
#                 score = out[1] if len(out) > 1 else 0
#                 id_conf = max(0, min(100, int(score)))
#     except Exception:
#         pass
#     return name, int(score), int(id_conf)

# # --- BreedIndexer (full) ---
# import cv2
# import numpy as np
# import torch
# import torchvision.transforms as T
# from torchvision import models
# from PIL import Image
# from collections import defaultdict

# class BreedIndexer:
#     """
#     - ë“±ë¡ ì»¬ëŸ¬ ì´ë¯¸ì§€ë¡œ í’ˆì¢…ë³„ ì„ë² ë”©(ResNet50 feature) ì„¼íŠ¸ë¡œì´ë“œ ê³„ì‚°
#     - ROIì—ì„œ ì„ë² ë”© ì¶”ì¶œ í›„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ í’ˆì¢… ì˜ˆì¸¡
#     - í•œê¸€ breed ë¼ë²¨ë„ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥ (ë¬¸ìì—´ ì‹ë³„ì)
#     """
#     def __init__(self, color_images_by_name, pet_db, device='cpu'):
#         self.device = torch.device(
#             device if device else ('cuda' if torch.cuda.is_available() else 'cpu')
#         )

#         # --- torchvision ë²„ì „ í˜¸í™˜: ì‹ í˜•(Weights API) / êµ¬í˜•(pretrained=True) ëª¨ë‘ ì§€ì› ---
#         ResNet50_Weights = getattr(models, "ResNet50_Weights", None)
#         if ResNet50_Weights is not None:
#             # ì‹ í˜• API (torchvision >= 0.13~)
#             weights = ResNet50_Weights.DEFAULT  # í˜¹ì€ .IMAGENET1K_V2
#             self.model = models.resnet50(weights=weights)
#             self.model.fc = torch.nn.Identity()
#             self.model.eval().to(self.device)

#             # Weightsê°€ ì œê³µí•˜ëŠ” ê¶Œì¥ ì „ì²˜ë¦¬(Resize/CenterCrop/ToTensor/Normalize ë“±) ì‚¬ìš©
#             self.transform = weights.transforms()
#             self._expects_pil = True  # weights.transforms()ëŠ” PIL ì…ë ¥ì´ ì•ˆì „
#         else:
#             # êµ¬í˜• API (ì˜› torchvision)
#             self.model = models.resnet50(pretrained=True)
#             self.model.fc = torch.nn.Identity()
#             self.model.eval().to(self.device)

#             # í‘œì¤€ ImageNet ì •ê·œí™” íŒŒì´í”„ë¼ì¸
#             self.transform = T.Compose([
#                 T.ToPILImage(),         # PIL ë³€í™˜ í¬í•¨
#                 T.Resize(256),
#                 T.CenterCrop(224),
#                 T.ToTensor(),
#                 T.Normalize(mean=[0.485, 0.456, 0.406],
#                             std=[0.229, 0.224, 0.225]),
#             ])
#             self._expects_pil = False  # ìœ„ íŒŒì´í”„ë¼ì¸ì€ npâ†’PILë„ ìˆ˜ìš©

#         # ì´ë¦„ â†” í’ˆì¢… ë§¤í•‘
#         self.name_to_breed = {}
#         self.breed_to_names = defaultdict(list)
#         for name, meta in (pet_db or {}).items():
#             breed = (meta or {}).get('breed')
#             if not breed:
#                 continue
#             self.name_to_breed[name] = breed
#             self.breed_to_names[breed].append(name)

#         # --- í’ˆì¢…ë³„ ì„¼íŠ¸ë¡œì´ë“œ ê³„ì‚° ---
#         # ëª¨ë“  ì´ë¦„ì˜ ëª¨ë“  ì´ë¯¸ì§€ ì„ë² ë”©ì„ ê°™ì€ í’ˆì¢…ì— ëª¨ì•„ì„œ í‰ê·  â†’ ë‹¨ìˆœ/ê²¬ê³ 
#         breed_vecs = defaultdict(list)

#         with torch.no_grad():
#             for name, imgs in (color_images_by_name or {}).items():
#                 breed = self.name_to_breed.get(name)
#                 if not breed or not imgs:
#                     continue
#                 for bgr in imgs:
#                     emb = self._embed(bgr)  # L2-normalized
#                     if emb is not None:
#                         breed_vecs[breed].append(emb)

#         self.breed_centroids = {}
#         for breed, vecs in breed_vecs.items():
#             if not vecs:
#                 continue
#             mean_emb = np.mean(np.stack(vecs, axis=0), axis=0)
#             nrm = np.linalg.norm(mean_emb) + 1e-8
#             self.breed_centroids[breed] = (mean_emb / nrm).astype(np.float32)

#     def _embed(self, roi_bgr):
#         """
#         ROI(BGR, np.ndarray HxWx3) -> 2048ì°¨ì› L2-normalized ì„ë² ë”© (np.ndarray)
#         """
#         if roi_bgr is None or roi_bgr.size == 0:
#             return None
#         # OpenCVëŠ” BGR, torchvisionì€ RGB/PILì´ ì•ˆì „
#         rgb = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2RGB)

#         # ë³€í™˜ íŒŒì´í”„ë¼ì¸ì´ PILì„ ê¸°ëŒ€í•˜ëŠ” ê²½ìš°ë¥¼ ê³ ë ¤í•´ í•­ìƒ PILë¡œ ì „ë‹¬(ê°€ì¥ ì•ˆì „)
#         img_pil = Image.fromarray(rgb)

#         ten = self.transform(img_pil).unsqueeze(0).to(self.device)
#         with torch.no_grad():
#             feat = self.model(ten)  # [1, 2048]
#             emb = torch.nn.functional.normalize(feat, dim=1).squeeze(0).cpu().numpy()
#         return emb  # L2-normalized

#     def predict_breed(self, roi_bgr, topk=3):
#         """
#         ì…ë ¥ ROIì— ëŒ€í•´ í’ˆì¢… ìƒìœ„ kê°œë¥¼ ë°˜í™˜.
#         return: List[(breed: str, conf: float 0~1)]
#         confëŠ” ëª¨ë“  í’ˆì¢…ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ min-max ì •ê·œí™”í•œ ìƒëŒ€ ì ìˆ˜.
#         """
#         if not self.breed_centroids:
#             return []
#         q = self._embed(roi_bgr)
#         if q is None:
#             return []
#         scores = []
#         for breed, c in self.breed_centroids.items():
#             sim = float(np.dot(q, c))  # cosine (ë‘˜ ë‹¤ L2-normalized)
#             scores.append((breed, sim))
#         scores.sort(key=lambda x: x[1], reverse=True)

#         # min-max ì •ê·œí™”(ìƒëŒ€ì  0~1). í’ˆì¢…ì´ 1ê°œë¿ì´ë©´ 1.0
#         sims = np.array([s for _, s in scores], dtype=np.float32)
#         if len(sims) >= 2:
#             mn, mx = float(sims.min()), float(sims.max())
#             den = (mx - mn) + 1e-8
#             norm = [(b, (s - mn) / den) for (b, s) in scores[:max(1, topk)]]
#         else:
#             norm = [(scores[0][0], 1.0)]
#         return norm

#     def names_in_breed(self, breed):
#         """í•´ë‹¹ í’ˆì¢…ì— ë“±ë¡ëœ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜."""
#         return list(self.breed_to_names.get(breed, []))


# # -------------------- ë©”ì¸ --------------------
# def main(
#     input_dir="test_videos",
#     output_dir="result_videos",
#     pet_dir="pet_images",
#     pet_db_path="pet_db.json",
#     yolo_weights="yolov8n.pt",
#     yolo_conf=0.25,
#     device=None
# ):
#     os.makedirs(output_dir, exist_ok=True)

#     # ê°•ì•„ì§€ DB(ì„ íƒ)
#     pet_db = {}
#     if os.path.isfile(pet_db_path):
#         try:
#             with open(pet_db_path, "r", encoding="utf-8") as f:
#                 pet_db = json.load(f)
#                 print(f"[INFO] pet_db ë¡œë“œ: {len(pet_db)}ë§ˆë¦¬")
#         except Exception as e:
#             print("[WARN] pet_db.json ë¡œë“œ ì‹¤íŒ¨:", e)

#     # ë“±ë¡ ì´ë¯¸ì§€ ë¡œë“œ
#     registered_orb = load_registered_images(pet_dir, verbose=True)
#     print(f"[INFO] ë“±ë¡ëœ ê°•ì•„ì§€(ORB) ìˆ˜: {len(registered_orb)}")

#     # í’ˆì¢… ì„ë² ë”©ìš© ì»¬ëŸ¬ ì´ë¯¸ì§€ ë¡œë“œ
#     registered_color = load_registered_color_images(pet_dir, verbose=True)
#     print(f"[INFO] ë“±ë¡ëœ ê°•ì•„ì§€(ì»¬ëŸ¬) ìˆ˜: {len(registered_color)}")

#     # Breed Indexer
#     breed_index = BreedIndexer(registered_color, pet_db, device=device or 'cpu')

#     # YOLO ë¡œë“œ
#     model = YOLO(yolo_weights)
#     if device is not None:
#         try:
#             model.to(device)
#             print(f"[INFO] YOLO device: {device}")
#         except Exception as e:
#             print("[WARN] device ì„¤ì • ì‹¤íŒ¨(ë¬´ì‹œí•˜ê³  ìë™ ì„ íƒ):", e)

#     videos = list_videos(input_dir)
#     if not videos:
#         print(f"[ERROR] ì²˜ë¦¬í•  ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
#         return

#     for vpath in videos:
#         vname = os.path.basename(vpath)
#         out_path = os.path.join(
#             output_dir,
#             os.path.splitext(vname)[0] + "_result.mp4"
#         )
#         print(f"\n[PROCESS] {vname} -> {out_path}")

#         cap = cv2.VideoCapture(vpath)
#         if not cap.isOpened():
#             print(f"[ERROR] ì—´ ìˆ˜ ì—†ëŠ” ì˜ìƒ: {vpath}")
#             continue

#         width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
#         height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
#         fps    = cap.get(cv2.CAP_PROP_FPS) or 30.0
#         fourcc = cv2.VideoWriter_fourcc(*"mp4v")
#         writer = cv2.VideoWriter(out_path, fourcc, fps, (width, height))

#         # íƒ€ì´ë° ê¸°ì¤€: "ì˜ìƒ ì‹œì‘ë¶€í„° í™•ì •ê¹Œì§€"
#         t0 = time.time()
#         confirmed_ms   = None
#         confirmed_name = None
#         confirmed_breed= None

#         # ì—°ì† í™•ì¸ ë²„í¼(í’ˆì¢…/ì´ë¦„ ë¶„ë¦¬)
#         breed_confirm_buf = []
#         name_confirm_buf  = []

#         frame_idx = 0
#         while True:
#             ret, frame = cap.read()
#             if not ret:
#                 break
#             frame_idx += 1

#             results = model(frame, conf=yolo_conf, verbose=False)
#             boxes = results[0].boxes

#             base_text = "No dog detected"
#             base_color = (0, 0, 255)
#             drawn = False

#             best = None  # ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ë°•ìŠ¤ ì„ íƒ
#             if boxes is not None and len(boxes) > 0:
#                 xyxy = boxes.xyxy.cpu().numpy()
#                 cls  = boxes.cls.cpu().numpy()
#                 conf = boxes.conf.cpu().numpy()

#                 for i in range(len(xyxy)):
#                     if int(cls[i]) != DOG_CLASS_ID:
#                         continue
#                     x1, y1, x2, y2 = xyxy[i]
#                     yolo_c = float(conf[i])
#                     x1, y1, x2, y2 = safe_rect(x1, y1, x2, y2, width, height)

#                     # ë°•ìŠ¤ì— 12~15% ì—¬ë°±ì„ ì¶”ê°€(íŠ¹ì§• ë” í™•ë³´)
#                     pad_x = int(0.12 * (x2 - x1))
#                     pad_y = int(0.12 * (y2 - y1))
#                     x1p = max(0, x1 - pad_x); y1p = max(0, y1 - pad_y)
#                     x2p = min(width-1, x2 + pad_x); y2p = min(height-1, y2 + pad_y)

#                     roi = frame[y1p:y2p, x1p:x2p]

#                     # 1) í’ˆì¢… ì˜ˆì¸¡ (top-1ë§Œ ì‚¬ìš©)
#                     breed_scores = breed_index.predict_breed(roi, topk=3)
#                     top_breed, breed_conf = (breed_scores[0] if breed_scores else (None, 0.0))

#                     # 2) ì´ë¦„ ë§¤ì¹­(í’ˆì¢…ìœ¼ë¡œ í›„ë³´ ì œí•œ)
#                     allowed = None
#                     if top_breed and breed_conf >= BREED_MIN_CONF:
#                         allowed = set(breed_index.names_in_breed(top_breed))
#                     name, match_score, id_conf = robust_match(roi, registered_orb, allowed_names=allowed)

#                     size = pet_db.get(name, {}).get("size", "unknown") if name else "unknown"

#                     # ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ í›„ë³´ ì €ì¥
#                     cand = {
#                         "name": name,
#                         "yolo_c": yolo_c,
#                         "id_conf": id_conf,
#                         "match_score": match_score,
#                         "rect": (x1, y1, x2, y2),
#                         "rect_pad": (x1p, y1p, x2p, y2p),
#                         "size": size,
#                         "breed": top_breed,
#                         "breed_conf": breed_conf
#                     }
#                     if best is None or yolo_c > best["yolo_c"]:
#                         best = cand

#             # í™•ì • ë¡œì§ ì²˜ë¦¬
#             if best is not None and confirmed_ms is None:
#                 # (a) í’ˆì¢… í™•ì •
#                 if best["breed"] and best["breed_conf"] >= BREED_MIN_CONF and best["yolo_c"] >= YOLO_MIN_CONF:
#                     breed_confirm_buf.append(best["breed"])
#                     if len(breed_confirm_buf) > CONFIRM_N:
#                         breed_confirm_buf.pop(0)
#                     if len(breed_confirm_buf) == CONFIRM_N and len(set(breed_confirm_buf)) == 1:
#                         confirmed_breed = breed_confirm_buf[-1]

#                 # (b) ì´ë¦„ í™•ì •(í’ˆì¢…ì´ í™•ì •ë˜ì—ˆê±°ë‚˜, id_confê°€ ì¶©ë¶„íˆ ë†’ì„ ë•Œ)
#                 if best["name"] and best["id_conf"] >= ID_MIN_CONF and best["yolo_c"] >= YOLO_MIN_CONF:
#                     name_confirm_buf.append(best["name"])
#                     if len(name_confirm_buf) > CONFIRM_N:
#                         name_confirm_buf.pop(0)
#                     if len(name_confirm_buf) == CONFIRM_N and len(set(name_confirm_buf)) == 1:
#                         confirmed_name = name_confirm_buf[-1]
#                         confirmed_ms = int((time.time() - t0) * 1000)
#                         print(f"[SUMMARY] {vname} confirmed_at={confirmed_ms}ms "
#                               f"(breed={confirmed_breed or best['breed']}, name={confirmed_name}, frames={CONFIRM_N})")
#                 else:
#                     # ì¡°ê±´ ë¯¸ì¶©ì¡±ì´ë©´ ì´ë¦„ ë²„í¼ë§Œ ì´ˆê¸°í™”(í’ˆì¢… ë²„í¼ëŠ” ìœ ì§€ ê°€ëŠ¥)
#                     name_confirm_buf.clear()

#             # ì‹œê°í™”
#             if best is not None:
#                 x1, y1, x2, y2 = best["rect"]
#                 if confirmed_ms is not None:
#                     color = (0, 255, 0)
#                     label = (f"CONFIRMED: {confirmed_name} ({confirmed_breed or best['breed']}) | "
#                              f"ID_Conf: {best['id_conf']}% | YOLO: {int(best['yolo_c']*100)}% "
#                              f"| BreedConf: {int(best['breed_conf']*100)}% | Size: {best['size']}")
#                 else:
#                     color = (0, 165, 255)  # í›„ë³´ ë‹¨ê³„
#                     btop = f"{best['breed']}({int(best['breed_conf']*100)}%)" if best['breed'] else "None"
#                     label = (f"Candidate: {best['name'] or 'None'} | Breed: {btop} | "
#                              f"ID_Conf: {best['id_conf']}% | YOLO: {int(best['yolo_c']*100)}% | Size: {best['size']}")
#                 cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
#                 cv2.putText(frame, label, (x1, max(20, y1-10)),
#                             cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
#                 drawn = True

#             if not drawn:
#                 cv2.putText(frame, base_text, (20, 40),
#                             cv2.FONT_HERSHEY_SIMPLEX, 1.0, base_color, 2)

#             # FPS í‘œì‹œ(ëŒ€ëµ)
#             elapsed = max(1e-6, (time.time() - t0))
#             fps_est = frame_idx / elapsed
#             cv2.putText(frame, f"FPS: {fps_est:.1f}", (20, height - 20),
#                         cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

#             writer.write(frame)

#         cap.release()
#         writer.release()
#         print(f"[DONE] ì €ì¥ ì™„ë£Œ: {out_path}")
#         if confirmed_ms is None:
#             print(f"[SUMMARY] {vname} confirmed_at=None (no stable confirmation)")

# if __name__ == "__main__":
#     ap = argparse.ArgumentParser()
#     ap.add_argument("--input_dir", default="test_videos")
#     ap.add_argument("--output_dir", default="result_videos")
#     ap.add_argument("--pet_dir", default="pet_images")
#     ap.add_argument("--pet_db", dest="pet_db_path", default="pet_db.json")
#     ap.add_argument("--weights", dest="yolo_weights", default="yolov8n.pt")
#     ap.add_argument("--conf", dest="yolo_conf", type=float, default=0.25)
#     ap.add_argument("--device", default=None, help="cuda:0 / mps / cpu / cuda:1 ...")
#     args = ap.parse_args()

#     main(
#         input_dir=args.input_dir,
#         output_dir=args.output_dir,
#         pet_dir=args.pet_dir,
#         pet_db_path=args.pet_db_path,
#         yolo_weights=args.yolo_weights,
#         yolo_conf=args.yolo_conf,
#         device=args.device
#     )


# # test_detect_dog.py
# import os
# import json
# import time
# import argparse

# import cv2
# import numpy as np
# import torch
# import torchvision.transforms as T
# from torchvision import models
# from PIL import Image, ImageDraw, ImageFont
# from ultralytics import YOLO

# from test_embedding_utils import (
#     load_registered_images,        # ORB descriptors
#     load_registered_color_images,  # BGR images for breed embedding
#     match_dog
# )

# # =========================
# # ì„¤ì • ê°’ (ì™„í™”ëœ ê¸°ë³¸ê°’)
# # =========================
# DOG_CLASS_ID      = 16   # COCO: dog
# VIDEO_EXTS        = (".mp4", ".mov", ".avi", ".mkv")

# YOLO_MIN_CONF     = 0.15  # YOLO í™•ì‹ ë„ ìµœì†Œ (0~1)
# ID_MIN_CONF       = 5     # ORB ID ì‹ ë¢°ë„ ìµœì†Œ (0~100)
# BREED_MIN_CONF    = 0.25  # í’ˆì¢… ì„ë² ë”© ì •ê·œí™” ì ìˆ˜(0~1)
# CONFIRM_N         = 2     # ê°™ì€ ê²°ê³¼ê°€ Ní”„ë ˆì„ ì—°ì†ì´ë©´ 'í™•ì •'

# DEBUG_PRINT_EVERY = 10    # Ní”„ë ˆì„ë§ˆë‹¤ ë””ë²„ê¹… ë¡œê·¸ ì¶œë ¥
# BREED_HIST_MAX    = 12    # í’ˆì¢… íˆìŠ¤í† ë¦¬ ìµœëŒ€ ê¸¸ì´
# BREED_HIST_REQ    = 3     # ìµœì†Œ ë“±ì¥ íšŸìˆ˜
# BREED_HIST_RATIO  = 0.6   # ìµœë¹ˆ í’ˆì¢…ì´ ì°¨ì§€í•´ì•¼ í•˜ëŠ” ë¹„ìœ¨

# # (ì„ íƒ) í’ˆì¢… â†’ ê¸°ë³¸ ëŒ€í‘œ ì´ë¦„(ì •ì±…)
# DEFAULT_NAME_BY_BREED = {
#     # "ìš”í¬ì…”í…Œë¦¬ì–´": "ì‚ì‚",
#     # "í‘¸ë“¤": "ì¿ í‚¤",
#     # "ë§í‹°ì¦ˆ": "ì„¤ê¸°",
#     # "ë¦¬íŠ¸ë¦¬ë²„": "ë²¤ì§€",
#     # "ìŠ¤íŒ¨ë‹ˆì–¼": "ìœ¨ë¬´",
#     # "ì‚¬ëª¨ì˜ˆë“œ": "ëª¨ëª¨",
# }

# # =========================
# # ìœ í‹¸
# # =========================
# def list_videos(input_dir):
#     files = []
#     if not os.path.isdir(input_dir):
#         print(f"[ERROR] ì…ë ¥ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
#         return files
#     for root, _, fnames in os.walk(input_dir):
#         for fname in sorted(fnames):
#             if fname.lower().endswith(VIDEO_EXTS):
#                 files.append(os.path.join(root, fname))
#     return files

# def safe_rect(x1, y1, x2, y2, w, h):
#     x1 = max(0, min(int(x1), w-1))
#     y1 = max(0, min(int(y1), h-1))
#     x2 = max(0, min(int(x2), w-1))
#     y2 = max(0, min(int(y2), h-1))
#     if x2 <= x1: x2 = min(w-1, x1+1)
#     if y2 <= y1: y2 = min(h-1, y1+1)
#     return x1, y1, x2, y2

# def robust_match(roi_bgr, registered, allowed_names=None):
#     """
#     match_dogì´ (name, score) ë˜ëŠ” (name, score, id_conf) ë‘˜ ë‹¤ ëŒ€ì‘.
#     allowed_namesê°€ ì£¼ì–´ì§€ë©´ ê·¸ ì´ë¦„ë“¤ë§Œ ëŒ€ìƒìœ¼ë¡œ ì œí•œ.
#     """
#     subset = registered
#     if allowed_names is not None:
#         subset = {k: v for k, v in registered.items() if k in allowed_names}
#         if not subset:
#             subset = registered  # í’ˆì¢…ì— í•´ë‹¹ ì´ë¦„ í´ë”ê°€ ë¹„ë©´ ì „ì²´ë¡œ í›„í‡´

#     name, score, id_conf = None, 0, 0
#     try:
#         out = match_dog(roi_bgr, subset)
#         if isinstance(out, tuple):
#             if len(out) == 3:
#                 name, score, id_conf = out
#             elif len(out) == 2:
#                 name, score = out
#                 id_conf = max(0, min(100, int(score)))
#             else:
#                 name = out[0] if len(out) > 0 else None
#                 score = out[1] if len(out) > 1 else 0
#                 id_conf = max(0, min(100, int(score)))
#     except Exception:
#         pass
#     return name, int(score), int(id_conf)

# def draw_text_korean(frame_bgr, text, org, font_size=20, color_bgr=(0,165,255), stroke=2):
#     """cv2.putTextê°€ í•œê¸€ì„ ëª» ì°ëŠ” ë¬¸ì œ í•´ê²°: PILë¡œ ë Œë”ë§."""
#     font_paths = [
#         "/System/Library/Fonts/AppleSDGothicNeo.ttc",  # macOS
#         "/Library/Fonts/AppleGothic.ttf",
#         "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",  # Linux
#         "C:/Windows/Fonts/malgun.ttf",  # Windows
#     ]
#     font = None
#     for p in font_paths:
#         try:
#             font = ImageFont.truetype(p, font_size)
#             break
#         except Exception:
#             continue
#     if font is None:
#         # í°íŠ¸ê°€ ì—†ìœ¼ë©´ ì˜ì–´ë§Œì´ë¼ë„ í‘œê¸°
#         cv2.putText(frame_bgr, text, org, cv2.FONT_HERSHEY_SIMPLEX, 0.6, color_bgr, 2, cv2.LINE_AA)
#         return frame_bgr

#     img_pil = Image.fromarray(cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB))
#     draw = ImageDraw.Draw(img_pil)
#     x, y = org
#     # ì™¸ê³½ì„ 
#     if stroke and stroke > 0:
#         for dx in (-stroke, 0, stroke):
#             for dy in (-stroke, 0, stroke):
#                 if dx == 0 and dy == 0: 
#                     continue
#                 draw.text((x+dx, y+dy), text, font=font, fill=(0,0,0))
#     # ë³¸ë¬¸
#     b,g,r = color_bgr
#     draw.text((x, y), text, font=font, fill=(r,g,b))
#     return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

# def pick_name_by_breed(breed, breed_index, pet_db):
#     """í’ˆì¢…ë§Œ í™•ì •ëœ ê²½ìš° ëŒ€í‘œ ì´ë¦„ì„ ì •ì±…ì ìœ¼ë¡œ ì„ íƒ."""
#     # ì •ì±… ë§µ ìš°ì„ 
#     if breed in DEFAULT_NAME_BY_BREED and DEFAULT_NAME_BY_BREED[breed] in pet_db:
#         return DEFAULT_NAME_BY_BREED[breed]
#     # í•´ë‹¹ í’ˆì¢…ì— ë“±ë¡ëœ ì´ë¦„ë“¤
#     cand = breed_index.names_in_breed(breed)
#     if not cand:
#         return None
#     if len(cand) == 1:
#         return cand[0]
#     return sorted(cand)[0]  # ì‚¬ì „ìˆœ

# # =========================
# # í’ˆì¢… ì¸ë±ì„œ
# # =========================
# class BreedIndexer:
#     """
#     - ë“±ë¡ ì»¬ëŸ¬ ì´ë¯¸ì§€ë¡œ í’ˆì¢…ë³„ ì„ë² ë”©(ResNet50 feature) ì„¼íŠ¸ë¡œì´ë“œ ê³„ì‚°
#     - ROIì—ì„œ ì„ë² ë”© ì¶”ì¶œ í›„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ í’ˆì¢… ì˜ˆì¸¡
#     - í•œê¸€ breed ë¼ë²¨ë„ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥ (ë¬¸ìì—´ ì‹ë³„ì)
#     """
#     def __init__(self, color_images_by_name, pet_db, device='cpu'):
#         self.device = torch.device(device if device else ('cuda' if torch.cuda.is_available() else 'cpu'))

#         # torchvision ë²„ì „ í˜¸í™˜
#         ResNet50_Weights = getattr(models, "ResNet50_Weights", None)
#         if ResNet50_Weights is not None:
#             weights = ResNet50_Weights.DEFAULT  # ë˜ëŠ” IMAGENET1K_V2
#             self.model = models.resnet50(weights=weights)
#             self.model.fc = torch.nn.Identity()
#             self.model.eval().to(self.device)
#             self.transform = weights.transforms()  # ê¶Œì¥ ì „ì²˜ë¦¬
#         else:
#             self.model = models.resnet50(pretrained=True)
#             self.model.fc = torch.nn.Identity()
#             self.model.eval().to(self.device)
#             self.transform = T.Compose([
#                 T.ToPILImage(),
#                 T.Resize(256),
#                 T.CenterCrop(224),
#                 T.ToTensor(),
#                 T.Normalize(mean=[0.485, 0.456, 0.406],
#                             std=[0.229, 0.224, 0.225]),
#             ])

#         # ì´ë¦„ â†” í’ˆì¢… ë§¤í•‘
#         self.name_to_breed = {}
#         self.breed_to_names = {}
#         for name, meta in (pet_db or {}).items():
#             breed = (meta or {}).get('breed')
#             if not breed:
#                 continue
#             self.name_to_breed[name] = breed
#             self.breed_to_names.setdefault(breed, []).append(name)

#         # í’ˆì¢…ë³„ ì„¼íŠ¸ë¡œì´ë“œ
#         breed_vecs = {}
#         for breed in self.breed_to_names.keys():
#             breed_vecs[breed] = []

#         with torch.no_grad():
#             for name, imgs in (color_images_by_name or {}).items():
#                 breed = self.name_to_breed.get(name)
#                 if not breed or not imgs:
#                     continue
#                 for bgr in imgs:
#                     emb = self._embed(bgr)
#                     if emb is not None:
#                         breed_vecs[breed].append(emb)

#         self.breed_centroids = {}
#         for breed, vecs in breed_vecs.items():
#             if not vecs:
#                 continue
#             mean_emb = np.mean(np.stack(vecs, axis=0), axis=0)
#             mean_emb /= (np.linalg.norm(mean_emb) + 1e-8)
#             self.breed_centroids[breed] = mean_emb.astype(np.float32)

#     def _embed(self, roi_bgr):
#         """ROI(BGR) -> 2048ì°¨ì› L2-normalized ì„ë² ë”©"""
#         if roi_bgr is None or roi_bgr.size == 0:
#             return None
#         rgb = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2RGB)
#         img_pil = Image.fromarray(rgb)
#         ten = self.transform(img_pil).unsqueeze(0).to(self.device)
#         with torch.no_grad():
#             feat = self.model(ten)  # [1, 2048]
#             emb = torch.nn.functional.normalize(feat, dim=1).squeeze(0).cpu().numpy()
#         return emb

#     def predict_breed(self, roi_bgr, topk=3):
#         """List[(breed, conf 0~1)] ë°˜í™˜. confëŠ” min-max ì •ê·œí™” ìƒëŒ€ ì ìˆ˜."""
#         if not self.breed_centroids:
#             return []
#         q = self._embed(roi_bgr)
#         if q is None:
#             return []
#         scores = []
#         for breed, c in self.breed_centroids.items():
#             sim = float(np.dot(q, c))  # cosine
#             scores.append((breed, sim))
#         scores.sort(key=lambda x: x[1], reverse=True)

#         sims = np.array([s for _, s in scores], dtype=np.float32)
#         if len(sims) >= 2:
#             mn, mx = float(sims.min()), float(sims.max())
#             den = (mx - mn) + 1e-8
#             norm = [(b, (s - mn) / den) for (b, s) in scores[:max(1, topk)]]
#         else:
#             norm = [(scores[0][0], 1.0)]
#         return norm

#     def names_in_breed(self, breed):
#         return list(self.breed_to_names.get(breed, []))

# # =========================
# # ë©”ì¸ ë£¨í”„
# # =========================
# def main(
#     input_dir="test_videos",
#     output_dir="result_videos",
#     pet_dir="pet_images",
#     pet_db_path="pet_db.json",
#     yolo_weights="yolov8n.pt",
#     yolo_conf=0.25,
#     device=None
# ):
#     os.makedirs(output_dir, exist_ok=True)

#     # pet DB
#     pet_db = {}
#     if os.path.isfile(pet_db_path):
#         try:
#             with open(pet_db_path, "r", encoding="utf-8") as f:
#                 pet_db = json.load(f)
#                 print(f"[INFO] pet_db ë¡œë“œ: {len(pet_db)}ë§ˆë¦¬")
#         except Exception as e:
#             print("[WARN] pet_db.json ë¡œë“œ ì‹¤íŒ¨:", e)

#     # ë“±ë¡ ì´ë¯¸ì§€
#     registered_orb = load_registered_images(pet_dir, verbose=True)
#     print(f"[INFO] ë“±ë¡ëœ ê°•ì•„ì§€(ORB) ìˆ˜: {len(registered_orb)}")

#     registered_color = load_registered_color_images(pet_dir, verbose=True)
#     print(f"[INFO] ë“±ë¡ëœ ê°•ì•„ì§€(ì»¬ëŸ¬) ìˆ˜: {len(registered_color)}")

#     # í’ˆì¢… ì¸ë±ì„œ
#     breed_index = BreedIndexer(registered_color, pet_db, device=device or 'cpu')

#     # YOLO
#     model = YOLO(yolo_weights)
#     if device is not None:
#         try:
#             model.to(device)
#             print(f"[INFO] YOLO device: {device}")
#         except Exception as e:
#             print("[WARN] device ì„¤ì • ì‹¤íŒ¨(ë¬´ì‹œí•˜ê³  ìë™ ì„ íƒ):", e)

#     videos = list_videos(input_dir)
#     if not videos:
#         print(f"[ERROR] ì²˜ë¦¬í•  ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
#         return

#     for vpath in videos:
#         vname = os.path.basename(vpath)
#         out_path = os.path.join(output_dir, os.path.splitext(vname)[0] + "_result.mp4")
#         print(f"\n[PROCESS] {vname} -> {out_path}")

#         cap = cv2.VideoCapture(vpath)
#         if not cap.isOpened():
#             print(f"[ERROR] ì—´ ìˆ˜ ì—†ëŠ” ì˜ìƒ: {vpath}")
#             continue

#         width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
#         height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
#         fps    = cap.get(cv2.CAP_PROP_FPS) or 30.0
#         fourcc = cv2.VideoWriter_fourcc(*"mp4v")
#         writer = cv2.VideoWriter(out_path, fourcc, fps, (width, height))

#         t0 = time.time()
#         confirmed_ms    = None
#         confirmed_name  = None
#         confirmed_breed = None

#         # ë²„í¼
#         breed_confirm_buf = []
#         name_confirm_buf  = []
#         breed_history     = []

#         frame_idx = 0
#         while True:
#             ret, frame = cap.read()
#             if not ret:
#                 break
#             frame_idx += 1

#             results = model(frame, conf=yolo_conf, verbose=False)
#             boxes = results[0].boxes

#             base_text = "No dog detected"
#             base_color = (0, 0, 255)
#             drawn = False

#             best = None  # ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ë°•ìŠ¤
#             if boxes is not None and len(boxes) > 0:
#                 xyxy = boxes.xyxy.cpu().numpy()
#                 cls  = boxes.cls.cpu().numpy()
#                 conf = boxes.conf.cpu().numpy()

#                 for i in range(len(xyxy)):
#                     if int(cls[i]) != DOG_CLASS_ID:
#                         continue
#                     x1, y1, x2, y2 = xyxy[i]
#                     yolo_c = float(conf[i])
#                     x1, y1, x2, y2 = safe_rect(x1, y1, x2, y2, width, height)

#                     # ì—¬ë°± ì¶”ê°€(íŠ¹ì§• í™•ë³´)
#                     pad_x = int(0.12 * (x2 - x1))
#                     pad_y = int(0.12 * (y2 - y1))
#                     x1p = max(0, x1 - pad_x); y1p = max(0, y1 - pad_y)
#                     x2p = min(width-1, x2 + pad_x); y2p = min(height-1, y2 + pad_y)
#                     roi = frame[y1p:y2p, x1p:x2p]

#                     # 1) í’ˆì¢… ì˜ˆì¸¡
#                     breed_scores = breed_index.predict_breed(roi, topk=3)
#                     top_breed, breed_conf = (breed_scores[0] if breed_scores else (None, 0.0))

#                     # 2) ì´ë¦„ ë§¤ì¹­(í’ˆì¢…ìœ¼ë¡œ í›„ë³´ ì œí•œ)
#                     allowed = None
#                     if top_breed and breed_conf >= BREED_MIN_CONF:
#                         allowed = set(breed_index.names_in_breed(top_breed))
#                     name, match_score, id_conf = robust_match(roi, registered_orb, allowed_names=allowed)

#                     size = pet_db.get(name, {}).get("size", "unknown") if name else "unknown"

#                     cand = {
#                         "name": name,
#                         "yolo_c": yolo_c,
#                         "id_conf": id_conf,
#                         "match_score": match_score,
#                         "rect": (x1, y1, x2, y2),
#                         "rect_pad": (x1p, y1p, x2p, y2p),
#                         "size": size,
#                         "breed": top_breed,
#                         "breed_conf": breed_conf
#                     }
#                     if best is None or yolo_c > best["yolo_c"]:
#                         best = cand

#             # í’ˆì¢… íˆìŠ¤í† ë¦¬ ëˆ„ì 
#             if best and best["breed"]:
#                 breed_history.append(best["breed"])
#                 if len(breed_history) > BREED_HIST_MAX:
#                     breed_history.pop(0)

#             # íˆìŠ¤í† ë¦¬ ê¸°ë°˜ í’ˆì¢… í™•ì •(ì´ë¦„ê³¼ ë³„ê°œ)
#             if confirmed_breed is None and len(breed_history) >= BREED_HIST_REQ:
#                 from collections import Counter
#                 cnt = Counter(breed_history)
#                 top_breed_hist, top_cnt = cnt.most_common(1)[0]
#                 if top_cnt >= max(BREED_HIST_REQ, int(BREED_HIST_RATIO * len(breed_history))):
#                     if best and best["breed"] == top_breed_hist and best["breed_conf"] >= BREED_MIN_CONF:
#                         confirmed_breed = top_breed_hist

#             # ì›ë˜ í™•ì • ë¡œì§
#             if best is not None and confirmed_ms is None:
#                 # (a) í’ˆì¢… ë²„í¼ ê¸°ë°˜ í™•ì •
#                 if best["breed"] and best["breed_conf"] >= BREED_MIN_CONF and best["yolo_c"] >= YOLO_MIN_CONF:
#                     breed_confirm_buf.append(best["breed"])
#                     if len(breed_confirm_buf) > CONFIRM_N:
#                         breed_confirm_buf.pop(0)
#                     if len(breed_confirm_buf) == CONFIRM_N and len(set(breed_confirm_buf)) == 1:
#                         confirmed_breed = breed_confirm_buf[-1]

#                 # (b) ì´ë¦„ í™•ì •
#                 if best["name"] and best["id_conf"] >= ID_MIN_CONF and best["yolo_c"] >= YOLO_MIN_CONF:
#                     name_confirm_buf.append(best["name"])
#                     if len(name_confirm_buf) > CONFIRM_N:
#                         name_confirm_buf.pop(0)
#                     if len(name_confirm_buf) == CONFIRM_N and len(set(name_confirm_buf)) == 1:
#                         confirmed_name = name_confirm_buf[-1]
#                         confirmed_ms = int((time.time() - t0) * 1000)
#                         print(f"[SUMMARY] {vname} confirmed_at={confirmed_ms}ms "
#                               f"(breed={confirmed_breed or best['breed']}, name={confirmed_name}, frames={CONFIRM_N})")
#                 else:
#                     name_confirm_buf.clear()

#             # í’ˆì¢…ë§Œ í™•ì •ë˜ë©´ ëŒ€í‘œ ì´ë¦„ìœ¼ë¡œ ì¦‰ì‹œ í™•ì • (fallback)
#             if confirmed_breed is not None and confirmed_name is None and best is not None:
#                 fallback = pick_name_by_breed(confirmed_breed, breed_index, pet_db)
#                 if fallback:
#                     confirmed_name = fallback
#                     confirmed_ms = int((time.time() - t0) * 1000)
#                     print(f"[SUMMARY] {vname} breed_confirmed={confirmed_breed} -> name_fallback={confirmed_name}")

#             # ë””ë²„ê·¸ ë¡œê·¸
#             if best is not None and (frame_idx % DEBUG_PRINT_EVERY == 0):
#                 print(f"[DBG] f={frame_idx} yolo={best['yolo_c']:.2f} "
#                       f"breed={best['breed']}({best['breed_conf']:.2f}) "
#                       f"name={best['name']} id={best['id_conf']}")

#             # ì‹œê°í™”
#             if best is not None:
#                 x1, y1, x2, y2 = best["rect"]
#                 if confirmed_ms is not None:
#                     color = (0, 255, 0)
#                     label = (f"í™•ì •: {confirmed_name} ({confirmed_breed or best['breed']}) | "
#                              f"ID:{best['id_conf']}% | YOLO:{int(best['yolo_c']*100)}% "
#                              f"| Breed:{int(best['breed_conf']*100)}% | Size:{best['size']}")
#                 else:
#                     color = (0, 165, 255)
#                     btop = f"{best['breed']}({int(best['breed_conf']*100)}%)" if best['breed'] else "None"
#                     label = (f"í›„ë³´: {best['name'] or 'ì—†ìŒ'} | í’ˆì¢…: {btop} | "
#                              f"ID:{best['id_conf']}% | YOLO:{int(best['yolo_c']*100)}% | Size:{best['size']}")
#                 cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
#                 frame = draw_text_korean(frame, label, (x1, max(20, y1-20)), font_size=20, color_bgr=color)
#                 drawn = True

#             if not drawn:
#                 frame = draw_text_korean(frame, base_text, (20, 40), font_size=22, color_bgr=base_color)

#             # FPS í‘œì‹œ
#             elapsed = max(1e-6, (time.time() - t0))
#             fps_est = frame_idx / elapsed
#             cv2.putText(frame, f"FPS: {fps_est:.1f}", (20, height - 20),
#                         cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

#             writer.write(frame)

#         cap.release()
#         writer.release()
#         print(f"[DONE] ì €ì¥ ì™„ë£Œ: {out_path}")

#         # ìš”ì•½
#         if confirmed_ms is None and confirmed_breed is None:
#             print(f"[SUMMARY] {vname} confirmed_at=None (no stable confirmation)")
#         elif confirmed_ms is None and confirmed_breed is not None:
#             print(f"[SUMMARY] {vname} breed_confirmed={confirmed_breed} (name not confirmed)")

# if __name__ == "__main__":
#     ap = argparse.ArgumentParser()
#     ap.add_argument("--input_dir", default="test_videos")
#     ap.add_argument("--output_dir", default="result_videos")
#     ap.add_argument("--pet_dir", default="pet_images")
#     ap.add_argument("--pet_db", dest="pet_db_path", default="pet_db.json")
#     ap.add_argument("--weights", dest="yolo_weights", default="yolov8n.pt")
#     ap.add_argument("--conf", dest="yolo_conf", type=float, default=0.25)
#     ap.add_argument("--device", default=None, help="cuda:0 / mps / cpu ë“± (ì„ íƒ)")
#     args = ap.parse_args()

#     main(
#         input_dir=args.input_dir,
#         output_dir=args.output_dir,
#         pet_dir=args.pet_dir,
#         pet_db_path=args.pet_db_path,
#         yolo_weights=args.yolo_weights,
#         yolo_conf=args.yolo_conf,
#         device=args.device
#     )

# test_detect_dog.py
import os
import json
import time
import argparse

import cv2
import numpy as np
import torch
import torchvision.transforms as T
from torchvision import models
from PIL import Image, ImageDraw, ImageFont
from ultralytics import YOLO

from test_embedding_utils import (
    load_registered_images,        # ORB descriptors
    load_registered_color_images,  # BGR images for breed embedding
    match_dog
)

# =========================
# ì„¤ì • ê°’ (ì™„í™”ëœ ê¸°ë³¸ê°’)
# =========================
DOG_CLASS_ID      = 16   # COCO: dog
VIDEO_EXTS        = (".mp4", ".mov", ".avi", ".mkv")

YOLO_MIN_CONF     = 0.15  # YOLO í™•ì‹ ë„ ìµœì†Œ (0~1)
ID_MIN_CONF       = 5     # ORB ID ì‹ ë¢°ë„ ìµœì†Œ (0~100)
BREED_MIN_CONF    = 0.25  # í’ˆì¢… ì„ë² ë”© ì •ê·œí™” ì ìˆ˜(0~1)
CONFIRM_N         = 2     # ê°™ì€ ê²°ê³¼ê°€ Ní”„ë ˆì„ ì—°ì†ì´ë©´ 'í™•ì •'

DEBUG_PRINT_EVERY = 10    # Ní”„ë ˆì„ë§ˆë‹¤ ë””ë²„ê¹… ë¡œê·¸ ì¶œë ¥
BREED_HIST_MAX    = 12    # í’ˆì¢… íˆìŠ¤í† ë¦¬ ìµœëŒ€ ê¸¸ì´
BREED_HIST_REQ    = 3     # ìµœì†Œ ë“±ì¥ íšŸìˆ˜
BREED_HIST_RATIO  = 0.6   # ìµœë¹ˆ í’ˆì¢…ì´ ì°¨ì§€í•´ì•¼ í•˜ëŠ” ë¹„ìœ¨

STOP_ON_CONFIRM   = True  # ì´ë¦„/í’ˆì¢… í™•ì •ë˜ë©´ ì¦‰ì‹œ ì €ì¥ í›„ ë‹¤ìŒ ì˜ìƒìœ¼ë¡œ
OVERLAY_FONT_SIZE = 20    # í•œê¸€ ì˜¤ë²„ë ˆì´ ê¸€ì í¬ê¸°

# (ì„ íƒ) í’ˆì¢… â†’ ê¸°ë³¸ ëŒ€í‘œ ì´ë¦„(ì •ì±…)
DEFAULT_NAME_BY_BREED = {
    # "ìš”í¬ì…”í…Œë¦¬ì–´": "ì‚ì‚",
    # "í‘¸ë“¤": "ì¿ í‚¤",
    # "ë§í‹°ì¦ˆ": "ì„¤ê¸°",
    # "ë¦¬íŠ¸ë¦¬ë²„": "ë²¤ì§€",
    # "ìŠ¤íŒ¨ë‹ˆì–¼": "ìœ¨ë¬´",
    # "ì‚¬ëª¨ì˜ˆë“œ": "ëª¨ëª¨",
}

# =========================
# ìœ í‹¸
# =========================
def list_videos(input_dir):
    files = []
    if not os.path.isdir(input_dir):
        print(f"[ERROR] ì…ë ¥ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
        return files
    for root, _, fnames in os.walk(input_dir):
        for fname in sorted(fnames):
            if fname.lower().endswith(VIDEO_EXTS):
                files.append(os.path.join(root, fname))
    return files

def safe_rect(x1, y1, x2, y2, w, h):
    x1 = max(0, min(int(x1), w-1))
    y1 = max(0, min(int(y1), h-1))
    x2 = max(0, min(int(x2), w-1))
    y2 = max(0, min(int(y2), h-1))
    if x2 <= x1: x2 = min(w-1, x1+1)
    if y2 <= y1: y2 = min(h-1, y1+1)
    return x1, y1, x2, y2

def robust_match(roi_bgr, registered, allowed_names=None):
    """
    match_dogì´ (name, score) ë˜ëŠ” (name, score, id_conf) ë‘˜ ë‹¤ ëŒ€ì‘.
    allowed_namesê°€ ì£¼ì–´ì§€ë©´ ê·¸ ì´ë¦„ë“¤ë§Œ ëŒ€ìƒìœ¼ë¡œ ì œí•œ.
    """
    subset = registered
    if allowed_names is not None:
        subset = {k: v for k, v in registered.items() if k in allowed_names}
        if not subset:
            subset = registered  # í’ˆì¢…ì— í•´ë‹¹ ì´ë¦„ í´ë”ê°€ ë¹„ë©´ ì „ì²´ë¡œ í›„í‡´

    name, score, id_conf = None, 0, 0
    try:
        out = match_dog(roi_bgr, subset)
        if isinstance(out, tuple):
            if len(out) == 3:
                name, score, id_conf = out
            elif len(out) == 2:
                name, score = out
                id_conf = max(0, min(100, int(score)))
            else:
                name = out[0] if len(out) > 0 else None
                score = out[1] if len(out) > 1 else 0
                id_conf = max(0, min(100, int(score)))
    except Exception:
        pass
    return name, int(score), int(id_conf)

def draw_text_korean(frame_bgr, text, org, font_size=OVERLAY_FONT_SIZE, color_bgr=(0,165,255), stroke=2):
    """cv2.putTextê°€ í•œê¸€ì„ ëª» ì°ëŠ” ë¬¸ì œ í•´ê²°: PILë¡œ ë Œë”ë§."""
    font_paths = [
        "/System/Library/Fonts/AppleSDGothicNeo.ttc",  # macOS
        "/Library/Fonts/AppleGothic.ttf",
        "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",  # Linux
        "C:/Windows/Fonts/malgun.ttf",  # Windows
    ]
    font = None
    for p in font_paths:
        try:
            font = ImageFont.truetype(p, font_size)
            break
        except Exception:
            continue
    if font is None:
        # í°íŠ¸ê°€ ì—†ìœ¼ë©´ ì˜ì–´ë§Œì´ë¼ë„ í‘œê¸°
        cv2.putText(frame_bgr, text, org, cv2.FONT_HERSHEY_SIMPLEX, 0.6, color_bgr, 2, cv2.LINE_AA)
        return frame_bgr

    img_pil = Image.fromarray(cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    x, y = org
    # ì™¸ê³½ì„ 
    if stroke and stroke > 0:
        for dx in (-stroke, 0, stroke):
            for dy in (-stroke, 0, stroke):
                if dx == 0 and dy == 0:
                    continue
                draw.text((x+dx, y+dy), text, font=font, fill=(0,0,0))
    # ë³¸ë¬¸
    b,g,r = color_bgr
    draw.text((x, y), text, font=font, fill=(r,g,b))
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

def draw_petdb_overlay(frame, name, breed, pet_db, org=(20, 20), line_gap=24, color_bgr=(0,255,0)):
    """í™•ì • í›„ pet_dbì˜ ì£¼ìš” ì •ë³´ë¥¼ í™”ë©´ì— ì—¬ëŸ¬ ì¤„ë¡œ ì˜¤ë²„ë ˆì´."""
    info = pet_db.get(name, {})
    fields = [
        f"ì´ë¦„: {name}",
        f"í’ˆì¢…: {breed}",
        f"ì²´êµ¬: {info.get('size', 'unknown')}",
        f"ëª¸ë¬´ê²Œ: {info.get('weight', '?')}kg",
        f"ë‚˜ì´: {info.get('age', '?')}ì„¸",
        f"í™œë™ê³„ìˆ˜: {info.get('activeLvl', '?')}",
        f"ì¹¼ë¡œë¦¬/ì¼(kgë‹¹): {info.get('calPerKg', '?')}",
        f"ê¸‰ì—¬ íšŸìˆ˜: {info.get('feedingCount', '?')}íšŒ",
    ]
    x, y = org
    for i, line in enumerate(fields):
        frame = draw_text_korean(frame, line, (x, y + i*line_gap), font_size=OVERLAY_FONT_SIZE, color_bgr=color_bgr)
    return frame

def pick_name_by_breed(breed, breed_index, pet_db):
    """í’ˆì¢…ë§Œ í™•ì •ëœ ê²½ìš° ëŒ€í‘œ ì´ë¦„ì„ ì •ì±…ì ìœ¼ë¡œ ì„ íƒ."""
    # 1) ì •ì±… ë§µ ìš°ì„ 
    if breed in DEFAULT_NAME_BY_BREED and DEFAULT_NAME_BY_BREED[breed] in pet_db:
        return DEFAULT_NAME_BY_BREED[breed]
    # 2) í•´ë‹¹ í’ˆì¢…ì— ë“±ë¡ëœ ì´ë¦„ë“¤
    cand = breed_index.names_in_breed(breed)
    if not cand:
        return None
    if len(cand) == 1:
        return cand[0]
    return sorted(cand)[0]  # ì‚¬ì „ìˆœ

# í™•ì • ì‹œ ì „ì†¡/ë¡œê¹… í›… (ì›í•˜ë©´ HTTP/MQTTë¡œ êµì²´)
def on_confirm(breed, name, pet_db, confirmed_ms):
    payload = pet_db.get(name) or {}
    print("[SEND]", {"breed": breed, "name": name, "ms": confirmed_ms, **payload})
    return payload  # [RESULT]ì— ì‚¬ìš©

# =========================
# í’ˆì¢… ì¸ë±ì„œ
# =========================
class BreedIndexer:
    """
    - ë“±ë¡ ì»¬ëŸ¬ ì´ë¯¸ì§€ë¡œ í’ˆì¢…ë³„ ì„ë² ë”©(ResNet50 feature) ì„¼íŠ¸ë¡œì´ë“œ ê³„ì‚°
    - ROIì—ì„œ ì„ë² ë”© ì¶”ì¶œ í›„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ í’ˆì¢… ì˜ˆì¸¡
    - í•œê¸€ breed ë¼ë²¨ë„ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥ (ë¬¸ìì—´ ì‹ë³„ì)
    """
    def __init__(self, color_images_by_name, pet_db, device='cpu'):
        self.device = torch.device(device if device else ('cuda' if torch.cuda.is_available() else 'cpu'))

        # torchvision ë²„ì „ í˜¸í™˜
        ResNet50_Weights = getattr(models, "ResNet50_Weights", None)
        if ResNet50_Weights is not None:
            weights = ResNet50_Weights.DEFAULT  # ë˜ëŠ” IMAGENET1K_V2
            self.model = models.resnet50(weights=weights)
            self.model.fc = torch.nn.Identity()
            self.model.eval().to(self.device)
            self.transform = weights.transforms()  # ê¶Œì¥ ì „ì²˜ë¦¬
        else:
            self.model = models.resnet50(pretrained=True)
            self.model.fc = torch.nn.Identity()
            self.model.eval().to(self.device)
            self.transform = T.Compose([
                T.ToPILImage(),
                T.Resize(256),
                T.CenterCrop(224),
                T.ToTensor(),
                T.Normalize(mean=[0.485, 0.456, 0.406],
                            std=[0.229, 0.224, 0.225]),
            ])

        # ì´ë¦„ â†” í’ˆì¢… ë§¤í•‘
        self.name_to_breed = {}
        self.breed_to_names = {}
        for name, meta in (pet_db or {}).items():
            breed = (meta or {}).get('breed')
            if not breed:
                continue
            self.name_to_breed[name] = breed
            self.breed_to_names.setdefault(breed, []).append(name)

        # í’ˆì¢…ë³„ ì„¼íŠ¸ë¡œì´ë“œ
        breed_vecs = {breed: [] for breed in self.breed_to_names.keys()}

        with torch.no_grad():
            for name, imgs in (color_images_by_name or {}).items():
                breed = self.name_to_breed.get(name)
                if not breed or not imgs:
                    continue
                for bgr in imgs:
                    emb = self._embed(bgr)
                    if emb is not None:
                        breed_vecs[breed].append(emb)

        self.breed_centroids = {}
        for breed, vecs in breed_vecs.items():
            if not vecs:
                continue
            mean_emb = np.mean(np.stack(vecs, axis=0), axis=0)
            mean_emb /= (np.linalg.norm(mean_emb) + 1e-8)
            self.breed_centroids[breed] = mean_emb.astype(np.float32)

    def _embed(self, roi_bgr):
        """ROI(BGR) -> 2048ì°¨ì› L2-normalized ì„ë² ë”©"""
        if roi_bgr is None or roi_bgr.size == 0:
            return None
        rgb = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2RGB)
        img_pil = Image.fromarray(rgb)
        ten = self.transform(img_pil).unsqueeze(0).to(self.device)
        with torch.no_grad():
            feat = self.model(ten)  # [1, 2048]
            emb = torch.nn.functional.normalize(feat, dim=1).squeeze(0).cpu().numpy()
        return emb

    def predict_breed(self, roi_bgr, topk=3):
        """List[(breed, conf 0~1)] ë°˜í™˜. confëŠ” min-max ì •ê·œí™” ìƒëŒ€ ì ìˆ˜."""
        if not self.breed_centroids:
            return []
        q = self._embed(roi_bgr)
        if q is None:
            return []
        scores = []
        for breed, c in self.breed_centroids.items():
            sim = float(np.dot(q, c))  # cosine
            scores.append((breed, sim))
        scores.sort(key=lambda x: x[1], reverse=True)

        sims = np.array([s for _, s in scores], dtype=np.float32)
        if len(sims) >= 2:
            mn, mx = float(sims.min()), float(sims.max())
            den = (mx - mn) + 1e-8
            norm = [(b, (s - mn) / den) for (b, s) in scores[:max(1, topk)]]
        else:
            norm = [(scores[0][0], 1.0)]
        return norm

    def names_in_breed(self, breed):
        return list(self.breed_to_names.get(breed, []))

# =========================
# ë©”ì¸ ë£¨í”„
# =========================
def main(
    input_dir="test_videos",
    output_dir="result_videos",
    pet_dir="pet_images",
    pet_db_path="pet_db.json",
    yolo_weights="yolov8n.pt",
    yolo_conf=0.25,
    device=None
):
    os.makedirs(output_dir, exist_ok=True)

    # pet DB
    pet_db = {}
    if os.path.isfile(pet_db_path):
        try:
            with open(pet_db_path, "r", encoding="utf-8") as f:
                pet_db = json.load(f)
                print(f"[INFO] pet_db ë¡œë“œ: {len(pet_db)}ë§ˆë¦¬")
        except Exception as e:
            print("[WARN] pet_db.json ë¡œë“œ ì‹¤íŒ¨:", e)

    # ë“±ë¡ ì´ë¯¸ì§€
    registered_orb = load_registered_images(pet_dir, verbose=True)
    print(f"[INFO] ë“±ë¡ëœ ê°•ì•„ì§€(ORB) ìˆ˜: {len(registered_orb)}")

    registered_color = load_registered_color_images(pet_dir, verbose=True)
    print(f"[INFO] ë“±ë¡ëœ ê°•ì•„ì§€(ì»¬ëŸ¬) ìˆ˜: {len(registered_color)}")

    # í’ˆì¢… ì¸ë±ì„œ
    breed_index = BreedIndexer(registered_color, pet_db, device=device or 'cpu')

    # YOLO
    model = YOLO(yolo_weights)
    if device is not None:
        try:
            model.to(device)
            print(f"[INFO] YOLO device: {device}")
        except Exception as e:
            print("[WARN] device ì„¤ì • ì‹¤íŒ¨(ë¬´ì‹œí•˜ê³  ìë™ ì„ íƒ):", e)

    videos = list_videos(input_dir)
    if not videos:
        print(f"[ERROR] ì²˜ë¦¬í•  ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
        return

    for vpath in videos:
        vname = os.path.basename(vpath)
        out_path = os.path.join(output_dir, os.path.splitext(vname)[0] + "_result.mp4")
        print(f"\n[PROCESS] {vname} -> {out_path}")

        cap = cv2.VideoCapture(vpath)
        if not cap.isOpened():
            print(f"[ERROR] ì—´ ìˆ˜ ì—†ëŠ” ì˜ìƒ: {vpath}")
            continue

        width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps    = cap.get(cv2.CAP_PROP_FPS) or 30.0
        fourcc = cv2.VideoWriter_fourcc(*"mp4v")
        writer = cv2.VideoWriter(out_path, fourcc, fps, (width, height))

        t0 = time.time()
        confirmed_ms    = None
        confirmed_name  = None
        confirmed_breed = None

        # ë²„í¼ & íˆìŠ¤í† ë¦¬
        breed_confirm_buf = []
        name_confirm_buf  = []
        breed_history     = []

        # ê²°ê³¼ ë³´ê´€
        final_result = {
            "video": vname,
            "name": None,
            "breed": None,
            "ms": None,
            "payload": {}
        }

        frame_idx = 0
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            frame_idx += 1

            results = model(frame, conf=yolo_conf, verbose=False)
            boxes = results[0].boxes

            base_text = "No dog detected"
            base_color = (0, 0, 255)
            drawn = False

            best = None  # ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ë°•ìŠ¤
            if boxes is not None and len(boxes) > 0:
                xyxy = boxes.xyxy.cpu().numpy()
                cls  = boxes.cls.cpu().numpy()
                conf = boxes.conf.cpu().numpy()

                for i in range(len(xyxy)):
                    if int(cls[i]) != DOG_CLASS_ID:
                        continue
                    x1, y1, x2, y2 = xyxy[i]
                    yolo_c = float(conf[i])
                    x1, y1, x2, y2 = safe_rect(x1, y1, x2, y2, width, height)

                    # ì—¬ë°± ì¶”ê°€(íŠ¹ì§• í™•ë³´)
                    pad_x = int(0.12 * (x2 - x1))
                    pad_y = int(0.12 * (y2 - y1))
                    x1p = max(0, x1 - pad_x); y1p = max(0, y1 - pad_y)
                    x2p = min(width-1, x2 + pad_x); y2p = min(height-1, y2 + pad_y)
                    roi = frame[y1p:y2p, x1p:x2p]

                    # 1) í’ˆì¢… ì˜ˆì¸¡
                    breed_scores = breed_index.predict_breed(roi, topk=3)
                    top_breed, breed_conf = (breed_scores[0] if breed_scores else (None, 0.0))

                    # 2) ì´ë¦„ ë§¤ì¹­(í’ˆì¢…ìœ¼ë¡œ í›„ë³´ ì œí•œ)
                    allowed = None
                    if top_breed and breed_conf >= BREED_MIN_CONF:
                        allowed = set(breed_index.names_in_breed(top_breed))
                    name, match_score, id_conf = robust_match(roi, registered_orb, allowed_names=allowed)

                    size = pet_db.get(name, {}).get("size", "unknown") if name else "unknown"

                    cand = {
                        "name": name,
                        "yolo_c": yolo_c,
                        "id_conf": id_conf,
                        "match_score": match_score,
                        "rect": (x1, y1, x2, y2),
                        "rect_pad": (x1p, y1p, x2p, y2p),
                        "size": size,
                        "breed": top_breed,
                        "breed_conf": breed_conf
                    }
                    if best is None or yolo_c > best["yolo_c"]:
                        best = cand

            # í’ˆì¢… íˆìŠ¤í† ë¦¬ ëˆ„ì 
            if best and best["breed"]:
                breed_history.append(best["breed"])
                if len(breed_history) > BREED_HIST_MAX:
                    breed_history.pop(0)

            # íˆìŠ¤í† ë¦¬ ê¸°ë°˜ í’ˆì¢… í™•ì •(ì´ë¦„ê³¼ ë³„ê°œ)
            if confirmed_breed is None and len(breed_history) >= BREED_HIST_REQ:
                from collections import Counter
                cnt = Counter(breed_history)
                top_breed_hist, top_cnt = cnt.most_common(1)[0]
                if top_cnt >= max(BREED_HIST_REQ, int(BREED_HIST_RATIO * len(breed_history))):
                    if best and best["breed"] == top_breed_hist and best["breed_conf"] >= BREED_MIN_CONF:
                        confirmed_breed = top_breed_hist

            # ì›ë˜ í™•ì • ë¡œì§
            if best is not None and confirmed_ms is None:
                # (a) í’ˆì¢… ë²„í¼ ê¸°ë°˜ í™•ì •
                if best["breed"] and best["breed_conf"] >= BREED_MIN_CONF and best["yolo_c"] >= YOLO_MIN_CONF:
                    breed_confirm_buf.append(best["breed"])
                    if len(breed_confirm_buf) > CONFIRM_N:
                        breed_confirm_buf.pop(0)
                    if len(breed_confirm_buf) == CONFIRM_N and len(set(breed_confirm_buf)) == 1:
                        confirmed_breed = breed_confirm_buf[-1]

                # (b) ì´ë¦„ í™•ì •
                if best["name"] and best["id_conf"] >= ID_MIN_CONF and best["yolo_c"] >= YOLO_MIN_CONF:
                    name_confirm_buf.append(best["name"])
                    if len(name_confirm_buf) > CONFIRM_N:
                        name_confirm_buf.pop(0)
                    if len(name_confirm_buf) == CONFIRM_N and len(set(name_confirm_buf)) == 1:
                        confirmed_name = name_confirm_buf[-1]
                        confirmed_ms = int((time.time() - t0) * 1000)
                        payload = on_confirm(confirmed_breed or best['breed'], confirmed_name, pet_db, confirmed_ms)
                        final_result.update({
                            "name": confirmed_name,
                            "breed": confirmed_breed or best['breed'],
                            "ms": confirmed_ms,
                            "payload": payload
                        })
                        print(f"[SUMMARY] {vname} confirmed_at={confirmed_ms}ms "
                              f"(breed={final_result['breed']}, name={confirmed_name}, frames={CONFIRM_N})")
                        if STOP_ON_CONFIRM:
                            # ë§ˆì§€ë§‰ í”„ë ˆì„ì— pet_db ì •ë³´ ì˜¤ë²„ë ˆì´ í›„ ì €ì¥í•˜ê³  íƒˆì¶œ
                            x1, y1, x2, y2 = best["rect"]
                            cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)
                            frame = draw_petdb_overlay(frame, confirmed_name, final_result['breed'], pet_db, org=(20, 60))
                            writer.write(frame)
                            break
                else:
                    name_confirm_buf.clear()

            # í’ˆì¢…ë§Œ í™•ì •ë˜ë©´ ëŒ€í‘œ ì´ë¦„ìœ¼ë¡œ ì¦‰ì‹œ í™•ì • (fallback)
            if confirmed_breed is not None and confirmed_name is None and best is not None:
                fallback = pick_name_by_breed(confirmed_breed, breed_index, pet_db)
                if fallback:
                    confirmed_name = fallback
                    confirmed_ms = int((time.time() - t0) * 1000)
                    payload = on_confirm(confirmed_breed, confirmed_name, pet_db, confirmed_ms)
                    final_result.update({
                        "name": confirmed_name,
                        "breed": confirmed_breed,
                        "ms": confirmed_ms,
                        "payload": payload
                    })
                    print(f"[SUMMARY] {vname} breed_confirmed={confirmed_breed} -> name_fallback={confirmed_name}")
                    if STOP_ON_CONFIRM:
                        x1, y1, x2, y2 = best["rect"]
                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)
                        frame = draw_petdb_overlay(frame, confirmed_name, confirmed_breed, pet_db, org=(20, 60))
                        writer.write(frame)
                        break

            # ë””ë²„ê·¸ ë¡œê·¸
            if best is not None and (frame_idx % DEBUG_PRINT_EVERY == 0):
                print(f"[DBG] f={frame_idx} yolo={best['yolo_c']:.2f} "
                      f"breed={best['breed']}({best['breed_conf']:.2f}) "
                      f"name={best['name']} id={best['id_conf']}")

            # ì‹œê°í™”
            if best is not None:
                x1, y1, x2, y2 = best["rect"]
                if confirmed_ms is not None:
                    color = (0, 255, 0)
                    label = (f"í™•ì •: {confirmed_name} ({confirmed_breed or best['breed']}) | "
                             f"ID:{best['id_conf']}% | YOLO:{int(best['yolo_c']*100)}% "
                             f"| Breed:{int(best['breed_conf']*100)}% | Size:{best['size']}")
                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                    frame = draw_text_korean(frame, label, (x1, max(20, y1-20)), font_size=20, color_bgr=color)
                    # í™•ì •ëœ ì •ë³´ ìƒì„¸ ì˜¤ë²„ë ˆì´ (ë°•ìŠ¤ ì•„ë˜ìª½ì´ ì¢ìœ¼ë©´ ì¢Œì¸¡ ìƒë‹¨ ë“±ìœ¼ë¡œ ì¡°ì •)
                    frame = draw_petdb_overlay(frame, confirmed_name, confirmed_breed or best['breed'], pet_db, org=(20, 60))
                else:
                    color = (0, 165, 255)
                    btop = f"{best['breed']}({int(best['breed_conf']*100)}%)" if best['breed'] else "None"
                    label = (f"í›„ë³´: {best['name'] or 'ì—†ìŒ'} | í’ˆì¢…: {btop} | "
                             f"ID:{best['id_conf']}% | YOLO:{int(best['yolo_c']*100)}% | Size:{best['size']}")
                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                    frame = draw_text_korean(frame, label, (x1, max(20, y1-20)), font_size=20, color_bgr=color)
                drawn = True

            if not drawn:
                frame = draw_text_korean(frame, base_text, (20, 40), font_size=22, color_bgr=base_color)

            # FPS í‘œì‹œ
            elapsed = max(1e-6, (time.time() - t0))
            fps_est = frame_idx / elapsed
            cv2.putText(frame, f"FPS: {fps_est:.1f}", (20, height - 20),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

            writer.write(frame)

        cap.release()
        writer.release()
        print(f"[DONE] ì €ì¥ ì™„ë£Œ: {out_path}")

        # [RESULT] ìš”ì•½
        if final_result["name"] is None and confirmed_breed is None:
            print(f"[SUMMARY] {vname} confirmed_at=None (no stable confirmation)")
        else:
            print("\n[RESULT]")
            print(f"{vname} ê²°ê³¼")
            print(f"- í™•ì • ì‹œê°„: {final_result.get('ms') if final_result.get('ms') is not None else 'N/A'} ms")
            print(f"- ì´ë¦„: {final_result.get('name') or 'N/A'}")
            print(f"- í’ˆì¢…: {final_result.get('breed') or (confirmed_breed or 'N/A')}")
            payload = final_result.get("payload", {})
            for k in ["size", "weight", "age", "activeLvl", "calPerKg", "feedingCount"]:
                if k in payload:
                    print(f"- {k}: {payload[k]}")
            print("")  # ë¹ˆ ì¤„

if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("--input_dir", default="test_videos")
    ap.add_argument("--output_dir", default="result_videos")
    ap.add_argument("--pet_dir", default="pet_images")
    ap.add_argument("--pet_db", dest="pet_db_path", default="pet_db.json")
    ap.add_argument("--weights", dest="yolo_weights", default="yolov8n.pt")
    ap.add_argument("--conf", dest="yolo_conf", type=float, default=0.25)
    ap.add_argument("--device", default=None, help="cuda:0 / mps / cpu ë“± (ì„ íƒ)")
    args = ap.parse_args()

    main(
        input_dir=args.input_dir,
        output_dir=args.output_dir,
        pet_dir=args.pet_dir,
        pet_db_path=args.pet_db_path,
        yolo_weights=args.yolo_weights,
        yolo_conf=args.yolo_conf,
        device=args.device
    )
